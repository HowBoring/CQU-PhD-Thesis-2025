\documentclass[../main.tex]{subfiles}

\graphicspath{{../figures/}}
\usepackage[linesnumbered,ruled,vlined,resetcount,algochapter]{algorithm2e}

\begin{document}

\mychapter{知识图谱引导的多形式优化模型融合方法研究}
\label{sec:ch5-knowledge-guided-multi-form-optimization-for-llm-merging}

本章聚焦于大规模预训练模型的免重复训练融合挑战，特别是针对现有静态融合方法易导致参数冲突与“能力遗忘”，以及优化驱动方法在面对大规模、不平衡模型集时（$N \gg M$）遭遇“组合爆炸”与“冷启动”的核心瓶颈。为应对此问题，本章提出一种知识引导的多形式迁移优化框架（Knowledge-Guided Multi-Form Transfer Optimization, KG-MFTO）。该方法通过将复杂的全局融合问题分解为一系列循序渐进的子问题，并构建动态知识图谱与课程规划器，实现了跨融合任务的知识积累与高效迁移。本章首先介绍免重复训练模型融合领域中知识复用面临的挑战，随后详细阐述 KG-MFTO 框架的总体设计、核心的知识图谱建模、课程规划机制与知识引导的演化求解器，最后通过在多个基准上的大量实验验证该框架在提升融合效率与最终性能方面的有效性。

\mysection{引言}
\label{sec:ch5-1-introduction}

当前，LLM 经特定领域监督微调（Supervised Fine-Tuning, SFT）后，可展现出较强的专业能力。如何免重复训练的前提下，将多个此类专家模型的能力集成到一个统一的高性能模型中，已成为人工智能领域一个具有挑战性的课题。传统的范式，如对模型进行多任务联合训练或全参数再次微调，在现有的大模型尺度上计算成本较高。同时，许多模型仅以黑箱接口形式提供服务，其参数无法直接访问。这些因素共同凸显了研发高效、鲁棒的免重复训练（training-free）模型融合方法的现实需求。一个免重复训练融合框架可支持模块化复用现有知识，实现模型能力的按需组装。然而，LLMs 大量的参数及其蕴含的复杂知识，使得融合配置的搜索空间非常大。

早期的研究主要集中于静态的免重复训练融合算法。这类方法试图通过固定的算术规则来组合模型，例如，Wortsman 等人提出的 Model Soup \cite{modelsoupsaveraging_wortsman_2022} 通过对多模型权重进行直接平均，在特定条件下能提升性能；Task Arithmetic \cite{editingmodelstask_ilharco_2023} 则将模型融合视为对参数增量（任务向量）的算术运算。然而，这类简单的线性组合策略忽视了不同模型参数更新间的潜在冲突，直接平均往往导致模型性能退化或关键能力的“灾难性遗忘”。
为缓解参数冲突问题，后续研究提出了一系列“改进型”的静态融合策略。这些方法在执行融合前，先对模型参数进行预处理。例如，TIES-Merging \cite{tiesmergingresolving_yadav_2023} 在融合前对权重进行选择性裁剪和符号对齐；DARE \cite{languagemodelsare_yu_2024} 则受 Dropout 启发，对参数增量进行随机稀疏化后再求平均。这些预处理步骤在一定程度上减轻了冲突，但其融合过程本质上仍依赖于固定的启发式规则，而非针对特定目标进行自适应优化。

与上述基于规则的方法不同，另一类研究将模型融合视为一个优化问题，尝试搜索最优的融合配置。例如，利用贝叶斯优化 \cite{practicalbayesianoptimization_snoek_2012} 或演化算法 \cite{geneticalgorithms_holland_1992} 来搜索模型各层的最佳加权系数。这类优化驱动的方法展现了更好的适应性，证实了融合过程可以通过黑盒搜索来指导。然而，现有的优化驱动方法大多将融合视为单阶段（single-stage）任务，即试图一次性找到融合所有候选模型的全局最优参数。

上述方法主要在模型数量较少、任务维度较低的设定下研究。当待融合模型的数目和任务规模都不大且相当时，搜索空间相对可控，简单的融合方案尚可奏效。然而在现实应用中，可用的已微调专家模型数量往往远超评测任务的数量。实际场景呈现出模型数量远大于任务数量的不平衡局面：常用评测任务集相对稳定且规模有限，而领域专家模型则在不断产生。同一任务可能对应数十个表现各异、部分能力重叠又各有侧重的模型。此时，融合的难点不在于缺少模型技能，而在于如何高效地筛选、加权并整合大量模型。已有为小规模情形设计的方法难以直接扩展到这种大规模不平衡设定，尤其当它们每次融合都从冷启动开始、未能利用相关问题的解来指导当前搜索时，算法将面临指数级增长的组合空间。由此可见，有必要引入一种更有原则的框架，将全局融合问题系统性地分解，通过求解较小且易处理的子问题提取关系知识，并将其用于指导整体的优化过程。

为此，本章将模型融合问题置于多形式迁移优化（Multi-Form Transfer Optimization, MFTO）的范式下重新审视\cite{evolutionarytransferoptimization_tan_2021}。MFTO 方法论旨在将复杂优化任务分解为一组更简单的辅助问题（称为形式），这些形式可视作对原问题的不同局部近似或约束版本，并允许在彼此之间共享解和知识。本章中，免重复训练的大模型融合被视为 MFTO 问题：与其尝试一步到位地求解全局融合，不如设计一系列逐步升级的融合子任务，每个子任务涉及模型或任务的一个子集，或施加特定约束，使其更易于求解。通过逐一解决这些子问题，可在受控环境下探查模型之间的局部协同或冲突模式，并将这些中间解和关系知识转移回来，指导全局融合的优化。

基于这一思路，本章提出了框架 KG-MFTO，即知识引导的多形式优化系统，用于免重复训练的大模型融合。KG-MFTO 包含三个核心模块：（1）一个动态演化的知识图谱，用图结构显式编码模型–模型和模型–任务间的关系信息；（2）一个课程规划器，基于知识图谱自适应地序列化各子融合问题，按信息增益最大化的顺序安排求解；（3）一个知识引导的演化求解器，融合领域知识以热启动 CMA-ES 演化算法，用来自知识图谱的先验指导搜索。通过这三者的配合，KG-MFTO 实现了优化过程中的持续知识积累与迁移：每当求解一个子问题后，系统都会将所得解及评估结果更新进知识图谱，提炼出模型协作或冲突的模式，再由课程规划器选择下一个最有价值的子问题，并由求解器利用已有知识高效搜索其最优融合配置。如此循环往复，整个融合过程形成一个“感知–计划–行动–学习”的闭环，在完全基于模型推理评价的条件下，实现对大规模模型融合问题的高效求解。

本章的主要贡献如下：首先，将大模型融合问题形式化为一个多形式迁移优化任务，避免了直接在高维参数空间进行暴力搜索；其次，设计并实现了以知识图谱为中心的 KG-MFTO 系统架构，用结构化记忆显式表示和传递各形式之间的知识；再次，提出一种课程引导的黑盒搜索策略：由课程规划器动态安排子问题序列构成优化课程，结合基于知识热启动的 CMA-ES 求解器，实现高效收敛；最后，通过大规模基准实验，验证了 KG-MFTO 在无需训练的情况下成功融合多个 LLM，在多个任务上性能达到或在部分任务上超过各单一模型，并且融合效率在多数设置下优于现有方法。消融实验进一步证实了知识图谱、课程规划和双重热启动求解器三者的互补作用。通过对关系知识的显式建模与跨子问题迁移，KG-MFTO 为实现可扩展的免重复训练模型融合提供了一种有原则且高效的途径。可以认为，该方法为机器学习中的复杂模型复用与组合问题提供了一种可行的视角。

本章余下内容组织如下：相关工作节介绍与本章研究相关的工作，包括模型无训练融合、任务分解与课程学习、迁移优化以及演化搜索等方面的进展；问题定义与多形式划分节形式化定义了模型融合问题并给出了多形式分解的思路；知识图谱驱动的理论框架节阐述了KG-MFTO的理论框架，包括知识图谱建模和图神经网络推理模块；KG-MFTO算法设计节详细描述了KG-MFTO的算法实现，包括课程规划、知识引导的演化求解器以及整体优化流程；实验与结果分析节给出了实验设置、结果与分析；最后对本章工作进行小结。

\mysection{问题背景与基础知识}
\label{sec:ch5-2-problem-background-and-basics}

\mysubsection{模型融合与组合}
\label{sec:ch5-2-1-model-merging-and-ensemble}

在免重复训练的条件下融合多个已训练模型，旨在以低成本方式汇聚不同模型的专业能力。根据其融合策略的特性，现有免重复训练融合方法的研究路径大致可以归纳为几个阶段。早期的研究主要集中于静态融合策略 (Static Merging Strategies)，这类方法基于固定的、预定义的算术规则来组合模型参数，不依赖于目标任务的反馈。最朴素的策略是模型平均（Model Averaging），例如 Wortsman 等人提出的 Model Soup~\cite{modelsoupsaveraging_wortsman_2022} 发现，对处于同一收敛盆地（convergence basin）的多个微调模型取权重平均，确实可以在不增加推理开销的情况下提升模型精度和鲁棒性。另一类代表性工作是任务算术 (Task Arithmetic) \cite{editingmodelstask_ilharco_2023}，它将微调模型视为“基础模型 + 任务向量（即参数增量）”的组合，通过对任务向量的算术运算来实现能力组合。此外，球面线性插值 (SLERP) \cite{shoemake1985slerp} 亦被用于在参数空间中沿球面路径插值模型，以产生更平滑的过渡。尽管上述静态方法简单易行，但它们的核心缺陷在于未考虑不同模型参数更新之间的潜在冲突，任意的线性加权或向量运算很可能导致参数干扰，使得融合后的模型性能迅速下降。

为缓解静态融合中的参数冲突问题，后续研究提出了一系列预处理-融合策略（Pre-processing-Merging Strategies）。此类方法在应用固定的融合规则（通常是平均）之前，增加参数预处理步骤，以减轻潜在冲突。例如，Yadav 等人 \cite{tiesmergingresolving_yadav_2023} 提出的 TIES-Merging 在融合任务向量前，执行裁剪（Trim）、对齐（Elect）和平均（Average）三步操作，以处理不同模型间参数更新的符号冲突与冗余。受 Dropout 启发，Yu 等人 \cite{languagemodelsare_yu_2024} 提出的 DARE 方法则在融合前对任务向量进行随机且大规模的稀疏化。这些通过参数“对齐”或“稀疏化”的预处理手段，在一定程度上提高了静态融合的鲁棒性。然而，它们依然依赖于启发式规则，缺乏针对最终融合性能的自适应优化过程。

与上述基于固定规则的方法不同，另一条研究路径将模型融合明确形式化为一个黑盒优化问题，即优化驱动的融合方法。这类方法定义一个目标函数（通常是融合模型在验证集上的性能指标），然后利用优化算法来搜索最佳的融合配置（例如融合权重、层间系数等）。例如 Akiba 等人提出的 EOMMR \cite{evolutionaryoptimizationmodel_akiba_2025} 尝试为模型的不同层或不同块搜索独立的加权系数，鉴于融合配置空间的高维、非凸特性，演化算法被引入来确定这些系数，用于在权重空间中高效搜索性能优异的融合方案。此类方法的实用价值也催生了 MergeKit \cite{mergekit_github} 等集成多种融合算法的开源工具包。

然而，上述所有方法几乎都局限于单阶段的融合范式。它们试图单阶段求解一个融合 $N$ 个模型（以在 $M$ 个任务上表现最优）的全局解。当 $N \gg M$ 且 $N$ 本身较大时，这种全局搜索将面临组合爆炸 (combinatorial explosion)，其本质上是 NP 难 (NP-hard) 的，导致全局最优解在计算上不可行。相比之下，本章工作（KG-MFTO）的出发点截然不同。我们不直接求解这个复杂的全局问题，而是将其分解为一系列更简单的、逐步演进的子问题（例如，从 2 个模型的融合开始）。通过引入多形式迁移优化（MFTO）框架，利用知识图谱在求解这些子问题的过程中积累和迁移关于“模型间协同与冲突模式”的知识，从而以课程学习的方式逐步引导搜索过程逼近全局最优解。这解决了现有方法在面对大规模、不平衡融合场景时的可扩展性难题。

\mysubsection{任务分解与课程式优化}
\label{sec:ch5-2-2-task-decomposition-curriculum-optimization}
将复杂任务分解并循序渐进求解的思想在机器学习中由来已久，即所谓课程学习。Bengio 等人在经典工作中表明，以从易到难的顺序呈现训练样本或任务，比起无序混合训练可以使模型收敛更快且泛化更好。虽然课程学习最常用于模型训练情景，其逐步加难的基本原则同样适用于一般优化问题。所提出的课程规划器借鉴了这一思想：先解决简单的子任务，再逐渐增加难度直至原始问题。在优化领域，这类似于分块坐标迭代等分而治之策略：通过交替优化部分变量、冻结其他变量，使高维问题分解为一系列低维问题来求解。然而，与简单的坐标下降不同，所提出的方法并非固定地循环优化各变量块，而是将每个子问题单独近似求解到较优解，并将这些部分解作为构件用于更复杂子问题的初始解或参考。某种意义上，该方法也体现了分层与模块化学习的思想：在多任务学习中，研究者有时会先训练若干子模型各自擅长不同任务，然后再将它们集成，这类似于首先求解小规模的模型子集或任务子集融合，再通过知识图谱将它们有机结合。通过显式地利用知识图谱记录各子解之间的联系，所提出的方法确保了子问题解最终能够一致地整合，而不是简单地各自求解却缺乏整合机制。

一个形象的类比是 Model Soup 的贪心融合过程：在该方法中，多个模型按照效果从高到低依次加入当前汤中，只有当加入下一个模型不会使验证性能下降时才将其纳入融合。这个过程实际形成了一个基于模型的手工课程：每次只融合当前最有价值的一个模型。该工作可以看作对此概念的泛化：不局限于每次加入单一模型，而是定义了丰富的子问题形式（例如“将模型 A 与 B 在任务 X 上融合”可以算作一种形式），并通过知识图谱和课程规划器自动地从大量候选中选择下一步要解决的融合子任务。这样的顺序并非预先固定的贪心，而是基于当前已经获取的知识由算法自适应决定，体现了一种自动课程学习的思想：序列的决定取决于学习者（对应求解器和知识图谱）的状态和进展。在该方法中，学习者的状态反映在知识图谱的内容上，而课程规划策略则利用这些知识（例如哪些模型组合尚不确定、哪些子问题的解对全局最有帮助）来选择下一个子任务。由此，任务分解和课程优化在融合问题求解中紧密结合，通过反馈环路实现：早期简单子任务的结果主动影响后续复杂子任务的选择和求解。

\mysubsection{迁移优化与多形式方法}
\label{sec:ch5-2-3-transfer-optimization-multi-form-methods}
本章工作深植于演化计算领域的迁移优化（Transfer Optimization, TO）思想。迁移优化旨在利用已解决的相关优化任务的经验来加速新任务的求解，其策略包括顺序迁移和多任务并行优化等。多任务优化允许算法在同一种群中同时演化多个任务的解，个体可以在不同任务之间迁移从而实现知识共享；而多形式迁移优化是近年来提出的一种框架，针对同一个问题的不同形式进行协同优化。所谓形式，是指对同一优化问题的某种变形或子问题，例如低保真度近似、约束松弛版本或子空间子问题等。在 MFTO 中，研究者人为构造出若干这样的形式，并行或交替地进行优化，同时在这些形式之间交换信息。不同形式共同构成了 MFTO 框架，算法通过共享种群或定期迁移个体，在形式之间传递有用的部分解和搜索经验。本章所述模型融合方法可视为 MFTO 在深度学习模型参数空间中的一次新颖应用。该方法所设计的每个子融合问题都是原始融合任务的一个受限版本，可能限定候选模型子集或任务子集，或降低优化维度。通过在一系列形式上进行优化，从而将原问题的搜索难度拆解，并在形式之间通过知识图谱这一共享记忆池实现知识迁移。值得注意的是，采用图结构来跟踪和指导跨形式的知识转移，这与以往 MFTO 实现多采用隐式迁移（如共享种群个体）有所不同。借助知识图谱，能够表达更加复杂的关系，例如“形式 A（模型 1+2 融合于任务 X）的解对于形式 B（模型 1+2+3 融合于任务 X）或形式 C（模型 1+2 融合于任务 Y）是相关的”，并据此有针对性地将形式 A 的解用作形式 B 或 C 的初始猜测。这种显式的知识跟踪与利用机制提升了迁移优化的效率。

需要强调的是，该方法与元学习有本质区别。广义的元学习同样是利用以往任务经验来加速新任务学习，但其典型框架（如 MAML~\cite{modelagnosticmeta_finn_2017}）假定任务来自某一分布，目标是学习一个对该分布中任意新任务都能快速适应的模型或初始化。相比之下，并不关心将来新的任务，也没有一个独立的“元训练、元测试”阶段，所要解决的是一个固定的目标问题：融合特定集合的模型来应对特定集合的任务。利用多种形式的划分只是为了更高效地解决这一单一问题，而不追求学习一个对其他问题通用的策略。因此，本章的方法严格来说不属于元学习，而是一次性优化过程中的内部迁移和课程机制。这一点有助于明确本章工作的定位：创新点在于如何将复杂融合问题分解并在其内部实现知识迁移，而非训练一个能推广到全新问题的元模型。换言之，KG-MFTO 解决的是一个定制的优化实例（虽然内部结构复杂），并不是一个跨任务的学习者。这一区别凸显了该工作的独特视角：通过对复杂问题内部结构的挖掘和利用，而非跨任务的经验泛化，来加速优化过程。

\mysubsection{知识引导的演化搜索}
\label{sec:ch5-2-4-knowledge-guided-evolutionary-search}
最后，该方法与演化算法在高维黑盒优化中的应用密切相关。演化算法和遗传算法因其不依赖梯度、易于全局搜索的特点，在优化神经网络权重和结构（即神经演化）方面有悠久历史。近年来，EA 被应用于神经结构搜索、超参数寻优，甚至用于大型模型权重优化等问题。例如，Real 等人表明演化策略能够发现卷积网络结构，其效果在实验设置下优于人工设计的网络 \cite{regularizedevolutionimage_real_2019}。这说明在复杂离散设计空间中，基于随机搜索的策略具有较大潜力。在模型融合任务中，前文提到已有尝试利用遗传算法搜索融合系数配置。所用求解器同样采用演化式搜索，但有两点关键区别：一是融入知识引导，二是细粒度多次搜索而非一次性全局搜索。首先，通过知识图谱这一载体，将领域知识注入演化过程。这类似于记忆型算法或带启发的 EA：在标准演化操作之外，引入特定领域的启发式以增强搜索效率。常见的方法包括辅助模型的引入，用代理模型预测适应度从而聚焦搜索。在类比下，知识图谱和图神经网络可被视为搜索空间的经验模型，能够提示哪些组合更可能有效。具体而言，利用知识图谱预测的解作为种群初始个体，并在变异/交叉时参考已知的优质部分解，从而使搜索不再盲目。其次，与以往对融合问题进行单次全局 EA 不同，在多个形式上运行较小规模的 EA，并通过知识图谱使它们协同。这有点类似协同演化的思想：将整体解拆分为若干子部分，各自演化，并定期组合评估整体适应度。在协同演化中，不同子种群优化不同部分变量，然后通过组合形成完整解评估。而所采用的形式优化可以看作动态协同演化：每个形式的演化搜索解决解的一个方面（例如部分模型的权重配置），知识图谱起到协调作用，确保这些部分最终汇集成一致的全局解。值得注意的是，近期有多任务演化研究开始利用图结构分析任务间的转移关系，这与所构建的图谱规划优化过程不谋而合。通过引入图结构的全局记忆，从而实现分布式且协调一致的搜索：多个演化进程在不同形式上并行展开，但通过知识图谱共享信息并共同收敛到统一的融合模型。

综合来看，该方法融合了模型融合、迁移优化与演化搜索的相关思路。将模型融合重新定型为 MFTO 问题，并引入知识驱动的机制（知识图谱与课程规划）来实现形式级别的知识迁移与共享，在一定程度上提升了搜索效率。下文将介绍 KG-MFTO 的方法论，包括如何构建知识图谱表示和课程式的优化过程，以及各模块的实现细节。随后，实验部分将验证本章方法在融合多个 LLM 方面的有效性，并通过与基线方法的比较展示其性能表现。

\mysection{问题定义与多形式划分}
\label{sec:ch5-3-problem-definition-and-form-decomposition}

首先，形式化模型融合问题，并引出多形式分解的求解思路。设有一组已微调的专家模型$\mathcal{M}=\{M_{1}, M_{2}, \ldots, M_{n}\}$，以及一组评估任务$\mathcal{T}=\{\tau_{1}, \tau_{2}, \ldots, \tau_{k}\}$（每个任务均有验证/测试数据）。定义一个免重复训练的融合算子$\mathrm{Merge}(\mathcal{M}, \boldsymbol{\alpha})$，它接受模型集合$\mathcal{M}$及相应融合系数向量$\boldsymbol{\alpha}\in \mathbb{R}^n$，输出融合后的模型参数。同时定义评价函数$\mathcal{F}$来度量融合模型在任务集$\mathcal{T}$上的综合性能。通常，$\mathcal{F}$可表示为各任务指标的加权和，如公式所示：
\begin{equation}
	\begin{aligned}
		\boldsymbol{\alpha}^{\star} & = \arg\max_{\boldsymbol{\alpha}\in\mathcal{C}} \mathcal{F}\Big(\mathrm{Merge}(\mathcal{M},\boldsymbol{\alpha}), \mathcal{T}\Big)                 \\
		{}                          & = \arg\max_{\boldsymbol{\alpha}\in\mathcal{C}} \sum_{j=1}^{k} w_j \text{Score}\Big(\mathrm{Merge}(\mathcal{M},\boldsymbol{\alpha}), \tau_j\Big),
	\end{aligned}
\end{equation}
其中，$\text{Score}(\cdot,\tau_j)$表示融合模型在任务$\tau_j$上的性能度量（如准确率、得分等），$w_j \ge 0$为对应的任务权重且$\sum_{j}w_j=1$，$\mathcal{C}$表示融合系数$\boldsymbol{\alpha}$需满足的约束空间（例如各系数非负且和为1的$n-1$维单纯形$\Delta^{n-1}$）。公式刻画了模型融合的目标：在不给定任何额外训练数据的情况下，通过调整融合权重$\boldsymbol{\alpha}$，使得合并模型在多任务验证集上的加权表现最优。

直接优化高维的$\boldsymbol{\alpha}$以满足目标是非常困难的。当模型数$N$和任务数$K$增大时，搜索空间呈指数级增长，并且不同模型在不同任务上的协同或冲突关系错综复杂，很难通过一次优化找到全局最优的融合配置。为应对这一挑战，本章引入了形式（Form）的概念，将全局融合问题分解为一系列子问题。每个形式 $f=(\mathcal{M}_f,\mathcal{T}_f)$ 由一个模型子集$\mathcal{M}_f \subseteq \mathcal{M}$和一个任务子集$\mathcal{T}_f \subseteq \mathcal{T}$组成，对应求解“仅融合 $\mathcal{M}_f$ 中的模型并在 $\mathcal{T}_f$ 上优化性能”的子任务。可以认为，全局问题本身也是一种形式；在理想情况下，通过若干子形式的求解可逐步逼近全局问题的最佳解。

为此，设定了一系列课程难度级别$\ell=2,3,\ldots,L$，其中$\ell$通常对应形式所包含的模型个数（亦即 $|\mathcal{M}_f|=\ell$）。课程学习理念在此体现为：从低级别（如$\ell=2$的简单模型对融合）开始，逐步提升$\ell$合并更多模型，从而增加问题难度。级别$\ell$的所有模型组合形式构成候选集合，在同级别的形式充分探索之后，再进入下一级别。当$\ell$增加时，问题规模越来越接近原始融合任务。通过这样的课程式子问题序列，可将复杂的全局优化逐步分解为一系列易于求解的小型优化问题。更重要的是，不同形式之间并非相互孤立，通过在较低级别形式中探索获得的部分解和关系知识，可指导更高一级别形式的搜索。例如，在 $\ell=2$ 级别可能发现模型 $M_a$ 与 $M_b$ 在某任务上协同效果较好，这一知识在 $\ell=3$ 级别包含 $M_a, M_b$ 的形式中依然有用；又或者可能在一个任务子集上应抑制某模型权重，这对包含更多任务的形式也有启发。要充分利用这种跨形式的知识转移，需要一种机制来记录和提炼各形式的解之间的关联。本章下一节将介绍所设计的动态知识图谱，用于作为中心枢纽在优化过程中累积和传播知识，从而将各子问题的解串联成一条完整的推理链，最终服务于全局融合目标的实现。

\mysection{知识图谱驱动的理论框架}
\label{sec:ch5-4-kg-driven-theoretical-framework}

本节描述 KG-MFTO 的理论支撑框架，包括用于跨形式知识共享的知识图谱表示和对图谱进行关系推理的图神经网络模型。知识图谱提供了一个全局视角来整合各子问题的信息，而图神经网络则学习图谱中的关系以预测新子问题的潜在结果和最佳解，从而为课程规划和求解提供指导。

\mysubsection{动态异构知识图谱建模}
\label{sec:ch5-4-1-dynamic-heterogeneous-kg-modeling}

本章构建了一个动态异构图 $G=(V,E)$ 来表示模型融合问题中的多种关系。图谱包含两类节点$V=\{\textsc{Model}, \textsc{Task}\}$，以及两类边$E=\{\textsc{Model--Model}, \textsc{Model--Task}\}$，分别对应模型之间的关系和模型与任务之间的关系。

节点表示：每个模型节点$M_i$（对应专家模型$M_i$）被赋予一个可训练的$d$维嵌入表示$\mathbf{h}^M_i \in \mathbb{R}^d$（初始随机化，在优化过程中更新）；每个任务节点$\tau_j$ 则使用一个固定的语义向量$\mathbf{h}^T_j \in \mathbb{R}^{d_T}$，该向量可通过预训练的句向量编码器（例如 SimCSE\cite{gao2021simcse}）从任务描述文本或名称计算得到。

边关系及统计量：知识图谱的边刻画了模型间以及模型与任务间的性能关联信息，并随优化过程动态更新。具体而言：

* 每条模型--模型边 $e(M_i, M_{i'})$ 维护两个实值统计量：协同分数 $s_{ii'}$ 和不确定度 $u_{ii'}$。直观地，$s_{ii'}$ 表示模型 $M_i$ 与 $M_{i'}$ 在当前已观察到的融合情形下的合作效果：若 $s_{ii'}$ 为正，表示两模型趋向于互补增益，为负则表示二者存在冲突互斥；$u_{ii'}$ 则表示当前关于 $s_{ii'}$ 的信息不确定程度，反映了对该对模型关系的了解程度。

* 每条模型--任务边 $e(M_i, \tau_j)$ 记录模型 $M_i$ 在任务 $\tau_j$ 上的性能指标 $\pi_{ij}$（例如验证集精度的指数滑动平均），以及可选的不确定性度量$\upsilon_{ij}$（例如性能的方差估计）。这些数据提供了每个模型在各任务上的擅长程度和稳定性。

知识图谱的边上统计量会在每次完成一个形式的评估后进行更新。假设当前求解了形式 $f=(\mathcal{M}_f,\mathcal{T}_f)$，得到融合配比$\boldsymbol{\alpha}_f$和该融合模型的验证集性能$y_f=\mathcal{F}(\mathrm{Merge}(\mathcal{M}_f,\boldsymbol{\alpha}_f), \mathcal{T}_f)$。据此更新图谱边上的统计量：首先，对于任意在 $\mathcal{M}_f$ 中共同出现的模型对 $(M_i, M_{i'})$，计算它们在该形式下的协同增益：
\begin{equation}
	g_f(i,i') = \Big(y_f - \bar{y}^{\text{ref}}_f\Big) \cdot \psi(\alpha_{f,i}, \alpha_{f,i'}),
\end{equation}
其中 $\bar{y}^{\text{ref}}_f$ 是一个参考基准得分，用于衡量本次融合结果相对于基线的提升程度（例如 $\bar{y}^{\text{ref}}_f$ 可取 $\mathcal{M}_f$ 中单个最好模型在 $\mathcal{T}_f$ 上的得分或所有模型简单平均融合的得分）；$\psi(\alpha_{f,i},\alpha_{f,i'})$ 则是一个用于度量模型 $M_i$ 与 $M_{i'}$ 共同贡献的函数，取值范围限定在$(-1,1)$。在简单情况下，可取 $\psi(a,b)=2ab$（当 $\boldsymbol{\alpha}$ 属于概率Simplex时，这表示两模型权重都较大时协同效应更强）。有了$g_f(i,i')$，采用滑动平均来更新协同分数：
\begin{equation}
	s_{ii'} \leftarrow (1-\lambda) s_{ii'} + \lambda g_f(i,i'),
\end{equation}
其中 $0<\lambda\ll 1$ 为平滑系数。通过持续积累不同形式中的协作增益$g_f(i,i')$，$s_{ii'}$ 将逐渐收敛到模型对 $(i,i')$ 在全局融合中的实际交互关系：若二者经常在一起出现在高性能融合解中，$s_{ii'}$ 会变为较大的正值；反之若二者共存时性能往往低于参考，$s_{ii'}$ 将趋向负值。

接下来，更新模型对的不确定度 $u_{ii'}$。一种简单的做法是记录该模型对在多少个不同形式中被观测到，然后根据观测次数递减不确定度。例如：
\begin{equation}
	\begin{aligned}
		n_{ii'} & \leftarrow n_{ii'} + \mathbb{I}\{i,i'\in\mathcal{M}_f\}, \\
		u_{ii'} & \leftarrow \frac{\kappa}{\kappa + n_{ii'}},
	\end{aligned}
\end{equation}
其中$\mathbb{I}(\cdot)$为指示函数，$n_{ii'}$ 累计了模型 $i$ 和 $i'$ 被一起包含于形式的次数，$\kappa$是初始虚拟观测次数（例如$\kappa=1$使得初始$u_{ii'}=0.5$）。这样，当某对模型尚未或很少被共同评估时，不确定度接近1；而随着其被考察次数增多，$u_{ii'}$ 单调减小，表示我们对其关系的信心提高。除了这种频次方法，亦可维护协同增益$g_f(i,i')$值的方差估计，将不确定度建模为方差的指数滑动平均$u_{ii'} \leftarrow \rho u_{ii'} + (1-\rho)\hat{\sigma}_{ii'}^2$，但无论采用何种策略，不确定度都会随证据增多而下降。

最后，对于每个参与当前形式的模型 $M_i\in \mathcal{M}_f$ 和任务 $\tau_j \in \mathcal{T}_f$，更新模型--任务边的性能指标$\pi_{ij}$，例如通过记录融合模型在任务$\tau_j$上的得分，或者对先前$\pi_{ij}$取加权平均。这一步可以视为对模型 $M_i$ 在任务 $\tau_j$ 上能力的重新校准：如果 $M_i$ 参与的融合在 $\tau_j$ 上取得了好的结果，说明 $M_i$ 对该任务可能有所助益；反之亦然。模型--任务边的不确定度$\upsilon_{ij}$亦可类似更新。

需要强调，知识图谱是随优化过程动态演化的：初始时我们对任何模型关系都不了解，可将所有 $s_{ii'}$ 设为0、$u_{ii'}$ 设为1（最大不确定）；随着逐步评估各种形式，图谱记录的信息愈加丰富，所包含的知识也愈加准确。知识图谱在整个融合求解过程中扮演全局记忆库的角色：它显式存储了各模型之间、模型与任务之间已经探明的关系，为后续未探明的组合提供指导依据。

\mysubsection{图神经网络的关系推理}
\label{sec:ch5-4-2-gnn-relational-reasoning}

有了上述知识图谱表示，进一步设计了一个异构图注意力网络来对图谱进行推理，预测未观察过的形式的性质。该 GNN 从图谱中提取与某候选形式 $f=(\mathcal{M}_f,\mathcal{T}_f)$ 相关的子图信息，并输出对该形式的性能、最优融合系数以及模型关系的预测。这为课程规划器选择形式和求解器热启动提供了关键依据。

具体而言，采用节点类型特定的线性变换将初始嵌入投影到共同空间：$\tilde{\mathbf{h}}^{M}_i = W_M \mathbf{h}^{M}_i$，$\tilde{\mathbf{h}}^{T}_j = W_T \mathbf{h}^{T}_j$，其中 $W_M \in \mathbb{R}^{d'\times d}$ 和 $W_T \in \mathbb{R}^{d'\times d_T}$。接下来，GNN 包含 $L$ 层图注意力网络（Graph Attention Networks，GAT）\cite{velickovic2018graph}，每层针对异构边类型分别计算注意力权重。对于模型--模型边，将边特征（如 $s_{ii'}$ 和 $u_{ii'}$）融合到注意力计算中，从而使具有高协同分数的模型节点对在消息传递时权重更高，而高不确定度可以暂时赋予其更大注意力以获取新信息；对于模型--任务边，则根据 $\pi_{ij}$ 权重来调整模型节点与任务节点之间的信息流强度。通过这种边权重调制的注意力机制，GNN 能够根据知识图谱中已有的关系数据，更加精准地聚合邻居信息。经过 $L$ 层传播后，获取了每个节点的高阶表示，记为 $\mathbf{z}^M_i$（模型节点）和 $\mathbf{z}^T_j$（任务节点）。

为了得到针对某一候选形式 $f$ 的预测，取出该形式诱导的子图，即包含 $\mathcal{M}_f$ 中的模型节点及 $\mathcal{T}_f$ 中的任务节点，以及它们之间的所有连边。然后，在这个子图上应用三个并行的输出头进行汇聚：

\textbf{（1）性能预测头}：对形式 $f$ 输出一个标量 $\hat{y}_f$，用于预测该形式在综合评价函数 $\mathcal{F}$ 下的得分。这可以通过对子图中的模型节点和任务节点的表示进行某种聚合来实现，例如将所有模型节点表示与任务节点表示拼接后通过多层感知机回归出 $\hat{y}_f$。希望 $\hat{y}_f$ 尽可能逼近真实的 $y_f$。

\textbf{（2）权重预测头}：输出形式 $f$ 中各模型的融合权重预测 $\hat{\boldsymbol{\alpha}}_f = (\hat{\alpha}_{f,i}: M_i \in \mathcal{M}_f)$。由于不同形式的 $\mathcal{M}_f$ 大小各异，采用自注意力机制实现对可变长度集的映射：具体地，引入一个轻量级 Transformer 编码器\cite{vaswani2017attention}，令形式中的每个模型节点表示 $\mathbf{z}^M_i$ 作为 Transformer 的输入序列，经若干注意力层后，输出维度与 $\mathcal{M}_f$ 大小相同，对应预测的每个模型权重 $\hat{\alpha}_{f,i}$（通过软 max 归一化使其和为 1）。这样设计可以根据模型节点间的相对关系来分配权重。这个头的作用是直接给出融合配置的建议，供后续求解器参考。

\textbf{（3）协同预测头}：输出形式 $f$ 中各模型对的协同矩阵 $\hat{S}_f \in \mathbb{R}^{m\times m}$（$m=|\mathcal{M}_f|$）。令该头输出对称矩阵，其中 $(\hat{S}_f)_{ii'}$ 反映模型 $M_i$ 与 $M_{i'}$ 在形式 $f$ 下的交互强弱预测。具体实现上，可以让每个模型节点最终表示 $\mathbf{z}^M_i$ 通过一个前馈网络映射到一个 $h$ 维向量，然后定义 $(\hat{S}_f)_{ii'} = \phi(\mathbf{q}_i^\top \mathbf{q}_{i'})$，其中 $\mathbf{q}_i$ 为模型 $M_i$ 对应的 $h$ 维向量，$\phi(\cdot)$ 为一个压缩函数（如双曲正切），以确保输出范围有限。协同预测头旨在提前估计当前形式内部模型两两之间是正协同（互补）还是负协同（冲突）。

图神经网络通过在线学习不断提高上述预测的准确性。每当一个形式 $f$ 被实际评估后，将其真实结果 $(y_f, \boldsymbol{\alpha}_f^\star)$ 作为训练样本，对 GNN 的参数进行更新。训练损失函数设计为同时兼顾三种预测的误差：
\begin{equation}
	\mathcal{L}_{\text{GNN}} =
	w_{\text{perf}}\big(\hat{y}_f - y_f\big)^2
	+
	w_{\alpha}\text{KL}\big(\boldsymbol{\alpha}_f^\star | \hat{\boldsymbol{\alpha}}_f\big)
	+
	w_{\text{syn}}\big|\hat{S}_f - S^{\text{KG}}_f\big|_F^2,
\end{equation}
其中 $w_{\text{perf}}, w_{\alpha}, w_{\text{syn}}$ 为超参数权重；$\text{KL}(\cdot|\cdot)$ 表示两个分布（向量经归一化后）的KL散度，用于度量预测的权重与当前已知最佳权重之间的差异；$|\cdot|_F$ 为Frobenius范数；$S^{\text{KG}}_f$ 为从当前知识图谱中提取的该形式的目标协同矩阵。例如可令 $(S^{\text{KG}}_f)_{ii'} = s_{ii'}$（对于 $i,i'\in \mathcal{M}_f$），即将当前图谱存储的协同分数作为期望值；或者简单地取 $S^{\text{KG}}_f$ 为0矩阵以鼓励 GNN 输出的小幅度。通过最小化损失，GNN 学会用自身的预测逼近知识图谱中的已有知识和当前求解得到的新知识。这里的KL散度项确保 GNN 建议的融合配比逐渐贴近目前观察到的最佳配比，从而提高日后对类似形式的指引作用；而协同矩阵误差项则让 GNN 内隐地学习模型对的相互作用规律。当不断有新形式解入图训练时，GNN 的预测性能会持续提升，进而帮助我们更好地评估和选择尚未探索的形式。换言之，图神经网络在整个优化过程中充当代理模型或导航员的角色：它将知识图谱中零散的关系数据综合为对新问题的预测，为何种组合值得尝试、该如何初始化解提供智能化建议。

通过知识图谱与图神经网络这两部分，构建了一个显式建模关系知识并随经验自我改进的理论框架。下一节中，将在此基础上介绍 KG-MFTO 的算法流程，包括如何利用 GNN 的预测来规划课程、选择形式，以及设计何种求解策略来充分利用这些知识进行融合优化。

\mysection{KG-MFTO算法设计}
\label{sec:ch5-5-kg-mfto-algorithm-design}

本节详细介绍 KG-MFTO 框架下各模块的算法实现，包括课程规划器用于候选形式的生成与选择，知识引导的演化求解器用于高效求解单个形式的最优融合配比，以及二者与知识图谱之间的闭环协作过程。整个算法遵循“感知-计划-执行-学习”的循环，将在伪代码和文字解释中展现这一闭环的具体运作。图\ref{fig:ch5-kg-mfto-framework} 展示了 KG-MFTO 的整体框架示意图。

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{KG-MFTO/KG-MFTO-framework.pdf}
	\bicaption[KG-MFTO算法框架]{KG-MFTO算法框架示意图。KG-MFTO通过动态知识图谱和图神经网络实现跨形式的知识共享与迁移，课程规划器负责生成和选择候选形式，演化求解器在每个形式上高效搜索最优融合配比。整个过程形成一个闭环，不断积累和利用经验以提升融合性能。}[Framework of KG-MFTO]{Illustration of the KG-MFTO algorithm framework. KG-MFTO enables cross-modal knowledge sharing and transfer through dynamic knowledge graphs and graph neural networks. A curriculum planner generates and selects candidate modalities, while an evolutionary solver efficiently searches for the optimal merging ratios within each modality. The entire process forms a closed loop that continuously accumulates and leverages experience to enhance merging performance.}\label{fig:ch5-kg-mfto-framework}
\end{figure}

\mysubsection{课程规划与形式选择}
\label{sec:ch5-5-1-curriculum-design-and-format}
在每次迭代中，KG-MFTO的课程规划器负责决定下一步要解决的子融合问题。规划器首先在当前课程级别$\ell$产生一组候选形式，然后利用图神经网络的预测值对这些候选进行评分，选出最优的形式提交给求解器。这样，规划器相当于在形式空间上进行了一步决策搜索，以期每次选择都能带来最大的信息增益和性能提升。

\mysubsubsection{候选形式生成}

给定当前课程级别 $\ell$，期望产生若干候选形式，每个形式包含 $\ell$ 个模型。为了高效探索形式空间，采用一种混合启发的随机生成策略。在生成每一个候选形式时，以一定概率从以下三种策略中选择一种：

\begin{itemize}[leftmargin=3\ccwd]
	\item \textbf{不确定性引导策略}（概率 $p_{\text{unc}}$）：随机选取当前知识图谱中不确定度最高的一对模型$(M_i, M_{i'})$，强制令其包含在形式中，然后随机加入其他 $\ell-2$ 个模型补足大小。这样得到的形式至少包含一个尚未充分探索过的模型对，旨在通过评估该形式来消除高不确定区域。
	\item \textbf{协同引导策略}（概率 $p_{\text{syn}}$）：先从图谱中选取某个模型$M_i$作为种子，然后基于当前 GNN 预测的协同矩阵 $\hat{S}$，贪婪地选择与$M_i$协同分数$\hat{s}_{ij}$较高的模型逐个加入，直至形成大小为$\ell$的一个强协同集合。直观上，这倾向于构造那些 GNN 已预测为可能有较强正协同效果的模型组合，以验证这些预测并在成功时快速累积性能。
	\item \textbf{随机策略}（概率 $1 - p_{\text{unc}} - p_{\text{syn}}$）：在剩余情况下，简单地在所有 $\binom{n}{\ell}$ 种大小为$\ell$的模型子集中均匀随机采样一个形式。这样可以保持探索的多样性，避免陷入仅依据当前预测的贪心选择。
\end{itemize}

此外，无论通过何种策略生成形式$f=(\mathcal{M}_f,\mathcal{T}_f)$，并相应选择一个任务子集$\mathcal{T}_f$。一般而言，令 $\mathcal{T}_f$ 尽量包含代表性的任务以全面评估性能，但在某些阶段也可采用聚焦策略，例如固定 $\mathcal{T}_f$ 为导致模型冲突最大的那几个任务，以专门优化那方面性能。为了确保比较的公平性，要求 $\mathcal{T}_f$ 至少覆盖全局评价函数 $\mathcal{F}$ 中涉及的主要指标。例如，在实验中，每个 $\mathcal{T}_f$ 都包含四大基准任务中的至少两个，以避免只优化单一任务导致偏离全局目标。

通过上述过程重复生成，直到收集到 $K$ 个候选形式 $\mathcal{C}_\ell$（$K$ 为预设候选池大小）。算法展示了候选形式生成的伪代码流程。需要注意的是，$K$ 并不需要很大，因为后续的评分选择将缩小范围；而且在生成过程中已注入启发式引导，使得这有限的候选中较大概率包含有价值的形式。

\begin{algorithm}[tb]
	\small
	\DontPrintSemicolon
	\KwIn{模型集 $\mathcal{M}$，任务集 $\mathcal{T}$，知识图谱 $G$，当前级别 $\ell$，候选池规模 $K$}
	\KwOut{候选形式集合 $\mathcal{C}_\ell$}
	$\mathcal{C}_\ell \leftarrow \emptyset$;
	\While{$|\mathcal{C}_\ell| < K$}{
		\eIf{\texttt{rand()} $< p_{\text{unc}}$}{
			从图谱中选取当前不确定度最高的模型对 $(M_u, M_{u'})$；\\
			设 $\mathcal{M}_f \leftarrow \{M_u, M_{u'}\}$ ；
		}{\eIf{\texttt{rand()} $< p_{\text{unc}} + p_{\text{syn}}$}{
				从$\mathcal{M}$中随机选取一个模型 $M_s$ 作为种子；\\
				依据当前$\hat{S}$将与 $M_s$ 协同值最高的 $\ell-1$ 个模型加入$\mathcal{M}_f$；
			}{
				从$\mathcal{M}$中均匀随机抽取 $\ell$ 个不同模型组成 $\mathcal{M}_f$；
			}}
		按需要选择 $\mathcal{M}_f$ 上的任务子集 $\mathcal{T}_f \subseteq \mathcal{T}$，确保覆盖主要评估指标；\\
		将 $f=(\mathcal{M}_f,\mathcal{T}_f)$ 加入 $\mathcal{C}_\ell$；
	}
	\Return{$\mathcal{C}_\ell$}
	\caption{候选形式生成 (级别 $\ell$)}
	\label{alg:candidates}
\end{algorithm}

形式评分与选择：一旦得到候选形式集 $\mathcal{C}_\ell$，利用上一节训练好的 GNN 对每个候选形式 $f\in\mathcal{C}_\ell$ 进行预测，并据此计算一个评分 $A(f)$ 来衡量其价值。采用类上置信界（UCB）的评分策略\cite{auer2002finite}：
\begin{equation}
	A(f) = \hat{y}_f + \beta_b \sigma(f),
\end{equation}
其中 $\hat{y}_f$ 是 GNN 性能头预测的形式 $f$ 综合得分，$\sigma(f)$ 则是对该形式不确定性的量化。将 $\sigma(f)$ 定义为形式 $f$ 中所有模型对边不确定度 $\{u_{ii'}: i,i'\in \mathcal{M}_f\}$ 的某种聚合，如简单平均或截断平均（去除最高和最低若干值后的均值），以代表 $f$ 内部关系知识的未知程度。$\beta_b$ 是一个随着迭代轮次 $b$ 递减的探索系数（例如 $\beta_b = \beta_0 / \sqrt{1+b}$），在算法初期保持较大以鼓励探索高不确定区域，后期逐渐减小以更加依赖模型预测的 $\hat{y}_f$ 进行利用。通过 UCB 评分，如果某形式的预期性能 $\hat{y}_f$ 很高则其评分自然高；同时如果某形式涉及的关系大多尚不明确（$\sigma(f)$ 高），其评分中也会加上一定的探索红利，鼓励算法尝试新组合获取知识。反之，如果形式的几乎所有关系都已有充分认知（$\sigma(f)$ 低），那么除非 $\hat{y}_f$ 非常高，否则规划器会倾向于选择别的形式，以避免重复探索收益有限的区域。可以看出，UCB 评分在这里平衡了性能导向和知识获取导向两种考虑。

计算出所有候选的 $A(f)$ 后，课程规划器从 $\mathcal{C}_\ell$ 中选出得分最高的形式 $f^\star = \arg\max_{f\in\mathcal{C}_\ell} A(f)$ 作为本次迭代的目标形式。随后，系统将把 $f^\star$ 交由融合求解器进行优化。值得一提的是，同时在规划器中设置了课程级别提升的判定条件：当当前级别 $\ell$ 的形式组合情况已较为充分地覆盖到下一级别 $\ell+1$ 的所有模型对时（例如对于 $\ell+1$ 级别涉及的每对模型，在 $\ell$ 级别至少观察过一次），则认为可以适时提升课程级别 $\ell \leftarrow \ell+1$。这样做是为了防止算法在低级别停留过久，从而能及时扩大组合规模，逐步接近全局融合问题。同时，这一条件确保在进入更高难度前，已对更小组合的关系有了基本了解，从而减小盲目性。课程级别提升通常与不确定度阈值或观察覆盖率等指标相关，可根据需要灵活设定。

\mysubsection{知识引导的演化求解器}
\label{sec:ch5-5-2-knowledge-guided-evolutionary-solver}
选定形式 $f^\star$ 后，需要在不给定梯度信息的情况下优化公式在该子问题上的目标，即求解：
$\boldsymbol{\alpha}^\star_{f^\star} = \arg\max_{\boldsymbol{\alpha}\in \mathcal{C}_{f^\star}} \mathcal{F}\Big(\mathrm{Merge}(\mathcal{M}_{f^\star}, \boldsymbol{\alpha}), \mathcal{T}_{f^\star}\Big),$
其中 $\mathcal{C}_{f^\star}$ 表示融合算子在形式 $f^\star$ 下的系数约束空间（例如 $\sum_{i\in \mathcal{M}_{f^\star}} \alpha_i = 1$ 且 $\alpha_i \ge 0$）。由于融合目标对 $\boldsymbol{\alpha}$ 来说是黑盒的且高度非凸，采用演化策略中的 CMA-ES 算法来执行这一优化搜索\cite{cmaevolutionstrategy_hansen_2016}。CMA-ES 是一种协方差矩阵自适应的演化算法，在连续参数优化中具有强大的全局搜索能力和鲁棒性。但为了充分利用本章框架中的知识，对 CMA-ES 进行了双重热启动：即通过知识图谱和 GNN 对目标形式的预测结果，初始化 CMA-ES 的搜索分布，使其从一个极具潜力的区域开始搜索，从而大幅减少试探开销。

在具体展开前，将融合系数的优化变量 $\boldsymbol{\alpha}$ 进行适当的参数化，使其对无约束演化算法更加友好。
若融合系数要求为概率分布（如简单平均），采用 Softmax 参数化。引入自由参数向量 $\mathbf{z}\in \mathbb{R}^m$（$m=|\mathcal{M}_{f^\star}|$），通过 $\alpha_i = \frac{\exp(z_i)}{\sum_{i'} \exp(z_{i'})}$ 将其映射到 $\Delta^{m-1}$ 单纯形。这确保无论如何搜索，$\boldsymbol{\alpha}$ 都满足非负和和为 1 的约束。为避免数值问题，可设定 $z_i$ 的上下界（如 $[-10,10]$）防止 softmax 输出极端 0 或 1。
若融合允许权重取正负（如对参数增量进行叠加的情形），采用 tanh 参数化。$\alpha_i = \frac{\tanh(z_i)}{\sum_{i'}|\tanh(z_{i'})|}$，这样 $z_i$ 任意实数均可通过 $\tanh$ 压缩在 $(-1,1)$，再归一化保证和为 1 的绝对值。直观上，这是对正负贡献进行归一的表示。

有了 $\mathbf{z}$ 的无约束表示，便可以在 $\mathbb{R}^m$ 上运行 CMA-ES。CMA-ES 以正态分布作为演化的候选分布，其核心在于每代更新分布的均值和协方差矩阵，使其逐步收敛到高适应度区域。在初始化时，需要给定一个起始均值 $\mathbf{m}_0$ 和一个初始协方差矩阵 $C_0$。这里，利用 GNN 预测的输出来设定它们：

\textbf{均值热启动}：将 GNN Alpha Head 输出的 $\hat{\boldsymbol{\alpha}}_{f^\star}$ 作为起点，即令 $\mathbf{m}_0 = \mathcal{R}(\hat{\boldsymbol{\alpha}}_{f^\star})$，其中 $\mathcal{R}(\cdot)$ 表示将融合权重逆映射到 $\mathbf{z}$ 空间的函数。对于 softmax 参数化，这相当于取 $\mathbf{m}_0$ 的各分量 $m_{0,i} = \log(\hat{\alpha}_{f,i} + \varepsilon)$ 减去平均值（$\varepsilon$ 为一个很小的数，如 1e-6，用于避免取对数时零值），以保证对应的 $\mathbf{z}$ 映射回 $\hat{\boldsymbol{\alpha}}_{f}$；对于 tanh 参数化，可取 $m_{0,i} = \tanh^{-1}(\hat{\alpha}_{f,i})$（将超出 $(-1,1)$ 范围的预测裁剪到 $-0.99,0.99$ 以计算反双曲正切）。这个初始化使得演化算法一开始就从 GNN 建议的融合配置附近开始搜索。$\hat{\boldsymbol{\alpha}}_{f^\star}$ 本身已经融合了知识图谱和过往形式解的信息，是较优解的预测，因此以其为中心启动搜索能够显著减少探索的盲目性。

\textbf{协方差热启动}：利用 GNN Synergy Head 输出的预测协同矩阵 $\hat{S}_{f^\star}$ 来设定初始协方差的相关结构。先将 $\hat{S}_{f^\star}$ 转换为相关矩阵：对于 $i \neq i'$，定义
\begin{equation}
	R_{ii'} = \phi\Big((\hat{S}_{f^\star})_{ii'}\Big),
\end{equation}
其中 $\phi(\cdot) = \tanh(\gamma \cdot)$ 是一个 S 型函数（$\gamma>0$ 为缩放因子），用于将预测协同值映射到 $(-1,1)$ 内，作为相关系数的近似。$R_{ii}=1$ 对角线元素保持为 1。由于 $\hat{S}_{f^\star}$ 可能不是正定矩阵，对 $R$ 做特征值分解 $R=Q\Lambda Q^\top$，将所有特征值 $\lambda_i$ 裁剪为非负（如 $\max(\lambda_i,\epsilon)$，$\epsilon$ 取 $10^{-6}$），再重构 $R$ 以确保其为半正定矩阵。最后选定一个初始尺度参数 $\sigma_0>0$，设置初始协方差矩阵为 $C_0 = \sigma_0^2 R$。这样产生的初始分布 $\mathcal{N}(\mathbf{m}_0, C_0)$ 具有以下意义：其均值在前述高潜力解附近，同时模型间的初始采样相关性反映了 GNN 预测的模型协同关系。若 $\hat{S}_{f^\star}$ 显示某两个模型高度正相关（可能需要一起取较大权重才能出好效果），则 $R$ 中对应的相关系数为正，使得它们的采样值倾向于同增同减；若协同为负，则产生负相关采样，使得它们的权重一增一减。这一协方差热启动有效地将知识图谱蕴含的模型依赖关系注入到随机搜索中，使 CMA-ES 更快找到满足协同约束的区域。

完成初始化后，运行 CMA-ES 对 $\mathbf{z}$ 进行迭代优化。在每次评价候选 $\mathbf{z}$ 时，先通过 $\mathrm{Proj}(\mathbf{z})$ 将其映射成融合系数 $\boldsymbol{\alpha}$，然后调用评估函数返回 $\mathcal{F}(\mathrm{Merge}(\mathcal{M}_{f^\star}, \boldsymbol{\alpha}), \mathcal{T}_{f^\star})$。为了减小评估噪声对搜索的影响，采用多次前向传播取中值的方式评估模型性能：对每个候选融合模型，在验证集上用不同随机种子跑多次前向推理，将这些分数取中位数作为该候选的适应度值（这相当于中值滤波，降低了随机因素或评价不稳定性的干扰）。CMA-ES 将根据这些适应度更新其内部的均值和协方差参数。当发现算法停滞（如连续 $G_{\text{stall}}$ 代没有更优解出现）时，触发信赖域重启：将协方差 $C$ 缩小，例如将 $\sigma_0$ 减半后重置 $C_0=\sigma_0^2 I$（或 $C$ 的对角线），从当前均值 $\mathbf{m}$ 重新开始局部搜索。这相当于在均值已近优、但协方差未充分收敛时，强行收缩搜索范围以 fine-tune 解。另一方面，如果观察到协方差矩阵的条件数急剧增大或者算法出现过早收敛迹象，也可能说明 GNN 提供的先验有误导，此时将采取降温措施：例如将 $C$ 与单位矩阵组合 $C \leftarrow (1-\eta)C + \eta \sigma^2 I$ 以降低相关性影响，或完全重置协方差为各维独立（对角矩阵）以重新探索。经过这些机制的增强，CMA-ES 通常能够高效逼近形式 $f^\star$ 的最优融合解。

算法 给出了知识引导求解器对单个形式进行优化的过程概要。最后输出的$\boldsymbol{\alpha}^\star_f$连同相应得分$y_f$将返回给主循环，用于更新知识图谱和训练GNN。

\begin{algorithm}[tb]
	\small
	\DontPrintSemicolon
	\KwIn{形式 $f=(\mathcal{M}_f,\mathcal{T}_f)$，GNN预测 $(\hat{y}_f,\hat{\boldsymbol{\alpha}}_f,\hat{S}_f)$，融合算子 $\mathrm{Merge}$，评价函数 $\mathcal{F}$}
	\KwOut{形式 $f$ 的最优融合方案 $\boldsymbol{\alpha}^\star_f$ 及其得分 $y_f$}
	$(\mathbf{m}_0,C_0)\leftarrow$ \textbf{WarmStart}$\big(\hat{\boldsymbol{\alpha}}_f, \hat{S}_f\big)$ \;
	$\displaystyle \boldsymbol{\alpha}^\star_f \leftarrow \textbf{CMA-ES}\Big(\mathbf{m}_0, C_0, \text{fitness}= \big\{\mathbf{z} \mapsto \mathcal{F}\big(\mathrm{Merge}(\mathcal{M}_f, \mathrm{Proj}(\mathbf{z})), \mathcal{T}_f\big)\big\}\Big)$ \;
	$y_f \leftarrow \mathcal{F}\Big(\mathrm{Merge}(\mathcal{M}_f, \boldsymbol{\alpha}^\star_f), \mathcal{T}_f\Big)$ \;
	\Return{$(\boldsymbol{\alpha}^\star_f,y_f)$}
	\caption{知识引导的融合求解器（单个形式）}
	\label{alg:solver}
\end{algorithm}

\mysubsection{闭环优化与图谱更新}
\label{sec:ch5-5-3-closed-loop-optimization-and-kg-update}
形式 $f^\star$ 求解完成后，KG-MFTO 进入学习步骤，即根据新获得的成果更新知识图谱和 GNN，从而完成一次闭环。具体步骤如下：首先，将形式 $f^\star$ 的解 $\boldsymbol{\alpha}^\star_{f^\star}$ 及其性能 $y_{f^\star}$ 用于更新知识图谱中的边属性：对于 $f^\star$ 中每一对模型 $(M_i,M_{i'})$，计算 $g_{f^\star}(i,i')=(y_{f^\star}-\bar{y}^{\text{ref}}_{f^\star})\cdot 2\alpha^\star_{f^\star,i}\alpha^\star_{f^\star,i'}$ 并相应地更新协同分数 $s_{ii'}$ 以及观测次数 $n_{ii'}$ 和不确定度 $u_{ii'}$；同时，对于 $f^\star$ 涉及的每个模型和任务，更新模型--任务性能 $\pi_{ij}$（例如取之前值与本次融合模型在任务 $\tau_j$ 表现的加权平均）。接着，以 $(f^\star,\boldsymbol{\alpha}^\star_{f^\star},y_{f^\star})$ 作为新的训练样本，对图神经网络执行数步梯度下降以最小化损失，更新 GNN 参数，使其能够重现该形式的结果。通过这一步，知识图谱和代理模型都更为“聪明”：图谱中显式存储了新的模型关系数据，GNN 则隐式将这些数据泛化为对其它潜在形式的更新预测。

完成学习后，检查课程级别是否需要调整：如前所述，若当前级别的形式探索已达到预设充分度且尚未达到最大级别，则令 $\ell \leftarrow \ell+1$，以便下次迭代生成更大规模的形式来求解。随后进入下一循环。整个闭环将持续运行直到耗尽预设的评估预算 $B$（即最多评估 $B$ 个形式的性能），或达到其它终止条件（如已找到全局融合的满意解）。最终，知识图谱中应已存有关于各模型关系的丰富知识，并获得了一系列所求解过的形式及其融合方案，其中最高级别（通常即全体模型）的融合方案即为最终目标所需的结果。算法 综合展示了 KG-MFTO 的完整流程。结果显示，课程规划、求解和图谱更新彼此交替，构成了一个自适应的闭环优化算法。

\begin{algorithm}[tb]
	\small
	\DontPrintSemicolon
	\KwIn{模型集 $\mathcal{M}$，任务集 $\mathcal{T}$，融合算子 $\mathrm{Merge}$，评估预算 $B$}
	\KwOut{得到解的形式集合及对应融合方案 $\{(f,\boldsymbol{\alpha}_f^\star,y_f)\}$}
	初始化知识图谱 $G$（节点包括$\mathcal{M}$和$\mathcal{T}$，边协同 $s_{ii'}=0$，不确定度 $u_{ii'}=1$ 等）；\ 初始化 GNN 参数（例如将 GNN 输出初始化为无偏估计：$\hat{y}\approx$单模型表现，$\hat{\boldsymbol{\alpha}}\approx$均匀分配，$\hat{S}\approx 0$）；\\
	设课程级别 $\ell\leftarrow 2$，已评估形式数 $b\leftarrow 0$；\\
	\While{$b < B$}{
		$\mathcal{C}_\ell \leftarrow \textbf{GenerateCandidates}(\mathcal{M},\mathcal{T},G,\ell,K)$
		\For{\textbf{each} $f \in \mathcal{C}_\ell$}{
			用当前 GNN 预测 $(\hat{y}_f,\hat{\boldsymbol{\alpha}}_f,\hat{S}_f)$；\\
			计算 $\displaystyle \sigma(f) = \text{Agg}\big(\{u_{ii'}: i,i'\in\mathcal{M}_f\}\big)$ （如取平均）；\\
			计算 $A(f) = \hat{y}_f + \beta_b\sigma(f)$ ；
		}
		选取 $f^\star = \arg\max_{f\in \mathcal{C}_\ell} A(f)$ 为本次迭代要评估的形式；\\
		$(\boldsymbol{\alpha}_{f^\star}^\star,y_{f^\star})\leftarrow \textbf{SolveForm}\big(f^\star,\hat{\boldsymbol{\alpha}}_{f^\star},\hat{S}_{f^\star},\mathrm{Merge},\mathcal{F}\big)$
		使用 $(f^\star,\boldsymbol{\alpha}_{f^\star}^\star,y_{f^\star})$ 更新知识图谱 $G$和训练 GNN；\\
		令 $b\leftarrow b+1$；
		\If{\textbf{需要提升级别}（依据累积观测覆盖率等）}{
			$\ell \leftarrow \ell + 1$；
		}
	}
	\caption{KG-MFTO：知识引导的多形式迁移优化算法流程}
	\label{alg:kg-mfto}
\end{algorithm}

\mysubsection{实践要点与扩展}
\label{sec:ch5-5-4-practical-considerations-extensions}
上述KG-MFTO算法框架在实践中可根据需要进行一些调整与扩展，以增强稳定性和适应不同场景：

\textbf{分层融合系数表示}：在某些融合算子中，允许针对模型的不同部分赋予不同权重（例如各 Transformer 层分别融合）。此时直接优化维度会变得极高。可对融合系数使用低秩结构参数化，例如令 $\alpha^{(\ell)}_i = \frac{\exp(a_i + b_\ell)}{\sum_{i'} \exp(a_{i'} + b_\ell)}$，将每个模型的整体重要性 $a_i$ 和每一层的偏置 $b_\ell$ 分别设为参数，加上小的交互项以增加表达能力。这样，优化变量从每层每模型一个，减少为每模型一个和每层一个，大幅降低维数。CMA-ES 即可以在 $\{a_i\}$ 和 $\{b_\ell\}$ 空间运行。通过这种方式，本章方法可拓展用于逐层（或模块）融合的情形，并通过知识图谱学习层级之间的模式。

\textbf{任务权重调整}：在多任务融合中，不同任务的评价尺度和可靠性可能差异较大。为防止某些任务主导优化或被忽略，可以对 $\mathcal{F}$ 的任务加权 $w_j$ 进行动态调整。例如，根据各任务得分的方差或不确定性设定 $w_j \propto 1/\widehat{\mathrm{Var}}(\text{Score}(\cdot,\tau_j))$，使评价更稳定；或在求和前对各任务分数进行排序归一化，以减小尺度差异带来的影响。这些技术有助于提升融合结果的任务公平性和稳健性。知识图谱中模型--任务边的性能不确定度 $\upsilon_{ij}$ 也可以用来辅助调整 $w_j$。

\textbf{冷启动与校准}：在优化开始时，由于没有任何形式评估数据，GNN 预测可能完全没有依据。通过对单模型行为的自监督预训练来初始化 GNN：令性能头预测 $\hat{y}_f$ 逼近选用单一模型时各任务的得分之和，Alpha 头输出接近“给予表现最佳的单模型以全部权重”，Synergy 头输出趋近 0 矩阵。这相当于告诉 GNN：在没有知识时，倾向于认为只有一个模型起主要作用，模型间既无特别协同也无特别冲突。这样初始化可避免 GNN 输出的无意义值误导初期搜索。此外，在 GNN 训练中采取措施防止过拟合，如对预测的 $\hat{\boldsymbol{\alpha}}$ 加噪声、对 $\hat{S}$ 加入微小随机扰动等，以增强模型对不确定区域的谨慎性。

\textbf{鲁棒性维护}：在迭代优化中，持续监控 CMA-ES 的协方差矩阵状况。如果发现其条件数过高（表示过度相关或尺度不均），采取对角加载方式正则化：令 $C \leftarrow (1-\eta)C + \eta(\sigma^2 I)$，其中 $\eta$ 取 $0.1\sim0.3$。这会略微拉回各方向的方差，防止数值不稳定。对于 softmax 参数映射，在将 $\mathbf{z}$ 转换为 $\boldsymbol{\alpha}$ 时也会对 $z_i$ 裁剪在一定范围内（如 $\pm \zeta$，$\zeta=10$），以避免出现极端概率值导致的梯度消失或算术下溢。在知识图谱更新协同分数时，对 $g_f(i,i')$ 也进行截断以防异常值（例如限制在 $[-1,1]$ 区间）。通过这些措施，保证整个优化过程的数值稳定性和鲁棒收敛。

\textbf{复杂度与效率}：每次迭代中，GNN 对候选形式的推理和评分计算的复杂度主要取决于候选数 $K$ 以及每个形式的子图大小 $m$。注意力汇聚的复杂度约为 $O(|E_f|d')$，其中 $|E_f|$ 通常随着 $m$ 增长近似 $O(m^2)$（完全图情况）。但由于 $m$ 一般不大（例如 $m$ 最大为十几到几十），并且 $K$ 也可以取一个中等值（如几十），因此这部分计算开销不大。CMA-ES 求解的瓶颈在于每代需要评估 $\lambda$ 个候选（$\lambda$ 为种群大小），每次评估涉及一次前向推理遍历任务数据。若每次融合评估的推理成本为 $T$，则 CMA-ES 每代成本 $O(\lambda T)$。幸运的是，由于知识引导大幅减少了迭代代数和 $\lambda$ 所需大小，实际在单个形式上消耗的评估次数很有限，且这些评估可以并行执行（在多 GPU/多线程环境下）。同时，通过课程规划的逐步推进，总的形式评估次数 $B$ 也显著小于直接全局搜索所需的评估次数，因此综合来看，KG-MFTO 在时间和算力上是可承受且可扩展的。实验中也将具体量化本章方法相较基线的效率提升。

综上所述，KG-MFTO 算法框架在设计上充分利用了知识迁移和课程优化的思想，通过知识图谱、GNN、课程规划和热启动求解的协同，实现了对免重复训练模型融合这一复杂问题的有效求解。下一节将在多个基准上验证本章方法的性能，比较不同策略的效果并分析其作用机制。

\mysection{实验与结果分析}
\label{sec:ch5-6-experiments-and-analysis}

通过一系列实验评估 KG-MFTO 在多 LLM 融合任务中的有效性。实验涵盖了不同领域的基准任务，并将本章方法与多种现有融合方案进行比较。同时，进行消融研究以验证知识图谱、课程规划等组件的作用，并分析 KG-MFTO 在融合过程中的效率优势和行为模式。

\mysubsection{实验设置}
\label{sec:ch5-6-1-experimental-setup}

\mysubsubsection{模型和任务}

选取 LLaMA-3.1-8B-Instruct 模型作为统一的基础模型（基座模型），并构建七个在不同领域数据上微调的专长模型（记为 M1--M7）。这些模型通过相同的 SFT 过程从基础模型 fine-tune 而来，只是训练数据各不相同，以确保模型结构与规模一致、差异仅来源于所习得的知识。表 列出了七个模型的领域及微调语料概况，包括：M1（英文指令执行），M2（中文问答），M3（数学解题），M4（代码生成），M5（常识推理），M6（科学问答）和 M7（对齐/安全）。这样选择旨在覆盖广泛而互补的能力范围。将所有这七个模型进行融合，以模拟一个复杂而具有高干扰风险的情形，同时挑选四类具有代表性的任务来评价最终融合模型的性能：

\begin{itemize}[leftmargin=3\ccwd]
	\item \textbf{指令遵循}（Instruction Following）：使用 IFEval 基准评估\cite{ifeval_zhou_2023}，指标为严格成功率（\%）。这类任务要求模型执行各种开放式指令，主要考察其实用对话能力。
	\item \textbf{多语种问答}（Multilingual QA）：使用 CMMLU 中文多任务集合\cite{li2023cmmlu}，取平均准确率（\%）作为指标。该集合涵盖中文的知识问答和推理题，考查模型的中文理解和知识覆盖面。
	\item \textbf{数学推理}（Mathematical Reasoning）：使用 MATH 高难度数学题库\cite{hendrycks2021math}，指标为问题解答正确率（\%）。这类任务需模型具备复杂的数学演算和逻辑推理能力。
	\item \textbf{代码生成}（Code Generation）：使用 HumanEval 编程能力评测集\cite{evaluatinglargelanguage_chen_2021}，采用 pass@1 准确率（\%）作为指标。该任务要求模型根据自然语言描述生成可执行且功能正确的 Python 函数，是评估语言模型代码生成能力的经典基准。
\end{itemize}


以上四项任务各自对应专长模型中的某一领域（例如 M4 专长代码，M3 专长数学等），也有交叉：如 M1 泛指令模型对所有有帮助，M2 中文知识模型对 CMMLU\cite{li2023cmmlu} 有贡献等等。因此，能否融合出在所有任务上均表现优异的模型，是对本章方法的严格考验。在每项任务上都有各自的测试集用于最终评估，在融合过程中则另准备了独立的验证集供算法评估使用。为了量化融合效果，引入性能保留率（Performance Retention Rate, PRR）指标：对于任务 $t$，有
\begin{equation}
	\text{PRR}(t) = \frac{S_{\text{merged}}(t)}{S_{\text{finetune}}(t)} \times 100\%,
\end{equation}
其中 $S_{\text{merged}}(t)$ 为融合模型在任务 $t$ 上的得分，$S_{\text{finetune}}(t)$ 则是对应领域的专家模型单独在该任务上的得分（即视各专长模型为上限，其自身在相应领域的能力为 100\%）。PRR 衡量融合模型相对于专家模型的能力保留程度。主要关注平均 PRR（四个任务的均值）作为整体指标，同时报告每个任务上的 PRR 及原始得分。

\begin{table}[tb]
	\centering\small
	\bicaption[专家模型概况]{七个微调的 LLaMA-3.1-8B 专家模型概况}[Expert models overview]{Overview of seven fine-tuned LLaMA-3.1-8B expert models}
	\label{tab:models}
	\small\begin{tabularx}{0.98\textwidth}{llL}
		\toprule
		\textbf{模型} & \textbf{专长领域} & \multicolumn{1}{c}{\textbf{微调数据集及描述}}                                                   \\
		\midrule
		M1          & 指令（英文）        & 英文通用指令遵循数据（如 Alpaca\cite{alpaca_2023}、Dolly\cite{dolly_2023}），训练模型以提供有用回答。              \\
		M2          & 中文问答          & 中文问答与推理数据（部分来源于 CMMLU 中文任务），提升模型非英文知识。                                                  \\
		M3          & 数学            & 数学问题求解语料（如 MATH\cite{hendrycks2021math}, GSM8K\cite{cobbe2021gsm8k} 等竞赛级题目），训练模型数学推理能力。 \\
		M4          & 代码            & 编程辅助数据（如 MBPP\cite{austin2021mbpp} Python题目），训练模型的代码生成和理解能力。                            \\
		M5          & 常识            & 常识推理语料（如 HellaSwag\cite{zellers2019hellaswag} 常识推理题），增强模型对日常场景的直觉判断。                    \\
		M6          & 科研问答          & 科学及学术问答数据（如 ARC\cite{clark2018arc}和 MMLU\cite{hendrycks2020mmlu}中科学领域题），赋予模型专业知识。       \\
		M7          & 对齐（安全）        & 多轮对话中有害内容拒答与守规数据（如 helpful/harmless 指令\cite{bai2022harmless}），提高模型道德规范。                 \\
		\bottomrule
	\end{tabularx}
\end{table}

\mysubsubsection{知识图谱与 GNN 配置}

构建的知识图谱包含 \( N = 7 \) 个模型节点（记为 \( M_1, \dots, M_N \)）和 4 个任务节点（对应前述四类任务）。初始时，所有模型–模型边的协同分数 \( s_{ii'} = 0 \)，不确定度 \( u_{ii'} = 1 \)；模型–任务边的性能 \( \pi_{ij} \) 设为模型 \( M_i \) 在任务 \( \tau_j \) 上单独推理所得的验证集得分（可通过各模型在验证集上独立推理一次获得）。图神经网络采用两层异构图注意力网络（GAT），每层包含 4 个注意力头，节点隐藏表示维度设为 128。表~\ref{tab:gat-hyperparams} 列出了 GNN 的超参数配置。训练过程中，每次形式评估后，对 GNN 执行 10 步 Adam 优化 \cite{adammethodstochastic_kingma_2015}（学习率 \( 1\times10^{-3} \)），以最小化复合损失函数。经验性地设定损失权重为 \( w_{\text{perf}} = 1 \)、\( w_{\alpha} = 0.5 \)、\( w_{\text{syn}} = 0.1 \)，以优先保障性能预测精度，同时兼顾对融合权重与协同关系的学习。得益于优化早期积累的样本，GNN 能迅速提供具有参考价值的预测结果，显著缩小形式选择与权重搜索的空间。

\begin{table}[tb]
	\centering\small
	\bicaption[GNN超参数配置]{图注意力网络模型的结构及训练超参数}[GNN hyperparameters]{Structure and training hyperparameters of the graph attention network model}
	\label{tab:gat-hyperparams}
	\small\begin{tabular}{ll}
		\toprule
		\textbf{超参数} & \textbf{取值 / 描述}                                     \\
		\midrule
		GNN层数        & 2 层异构图注意力（隐藏维度 128）                                  \\
		注意力头数        & 每层 4 头（输出拼接）                                         \\
		激活函数         & LeakyReLU（负斜率参数 0.2）                                 \\
		Dropout      & 0.2（用于注意力和前馈层）                                       \\
		优化方法         & Adam（学习率 \(1\times10^{-3}\)，权重衰减 \(1\times10^{-5}\)） \\
		训练步数         & 每新增样本后 10 步（早停策略监控损失）                                \\
		损失函数         & 均方误差 / KL散度 / Frobenius误差 复合                         \\
		\bottomrule
	\end{tabular}
\end{table}

\mysubsubsection{基线方法}

为全面评估 KG-MFTO 的性能，选取以下几种具有代表性的模型融合策略作为基线进行对比。所有方法均在融合全部 \( N = 7 \) 个模型的设定下进行评估：

\begin{itemize}[leftmargin=3\ccwd]
	\item \textbf{Model Soup} \cite{modelsoupsaveraging_wortsman_2022}：将所有 \( N \) 个模型的参数等权重平均，即 \( \theta_{\text{merged}} = \frac{1}{N}\sum_{i=1}^{N}\theta_{M_i} \)。这是最基础的融合策略。
	\item \textbf{Task Arithmetic} \cite{editingmodelstask_ilharco_2023}：对每个专家模型计算其相对于基础模型的参数增量 \( \Delta_i = \theta_{M_i} - \theta_{\text{base}} \)，然后融合为 \( \theta_{\text{merged}} = \theta_{\text{base}} + \frac{1}{N}\sum_{i=1}^{N} \Delta_i \)。该方法试图通过向量算术组合多个任务的参数更新。
	\item \textbf{TIES-Merging} \cite{tiesmergingresolving_yadav_2023}：首先对每个模型的参数增量进行修剪（保留 Top-\(K\) 幅度的参数，\( K = 0.3 \)）和符号对齐，再进行平均融合。采用原文推荐的超参数：Top-\(K\) 比例为 0.3，裁剪尺度 \( \lambda = 0.4 \)。
	\item \textbf{DARE} \cite{mergekit_github}：对每个模型的参数增量以 90\% 的概率随机置零，并将剩余参数放大 10 倍后进行平均融合。同时报告 DARE 与 TIES 结合的变体（先执行 DARE，再应用 TIES）。
	\item \textbf{EOMMR} \cite{evolutionaryoptimizationmodel_akiba_2025}：基于演化算法搜索融合权重的自适应方法。实现了一个改进的遗传算法：为每个模型分配一个全局权重 \( \alpha_i \) 及每层的细粒度权重，通过种群大小 30、演化代数 50 的迭代搜索最优配置。该方法计算开销较大（在本实验环境下约需 33 GPU 小时），但可视为强基线。
\end{itemize}

上述基线涵盖了从静态平均、启发式参数操作到自适应优化的多种融合范式。所有方法均在融合全部 \( N = 7 \) 个模型后，于各任务上评估其性能并计算 PRR。

\mysubsubsection{实现与环境}

本章方法以 PyTorch 实现，融合过程在 8 张 NVIDIA RTX4090 GPU 上并行运行。对于演化求解器，将 CMA-ES 种群评估过程分散到多卡上以加速。对于每个融合模型的性能评估，使用混合精度推理并缓存中间结果以减少重复计算。EOMMR 基线由于需要大量迭代评估，也采用多 GPU 并行实现。整体实验耗时方面，EOMMR 融合 7 模型耗时约 33 GPU 小时，而本章 KG-MFTO 包括图谱推理和多轮求解在内总耗时不足 2 GPU 小时，体现了显著的效率优势。

\mysubsection{融合性能比较}
\label{sec:ch5-6-2-merging-performance-comparison}

\begin{figure}
	\centering
	\includegraphics[width=0.67\textwidth]{KG-MFTO/figure1_perf_scaling.pdf}
	\bicaption[融合规模对跨任务性能的影响]{不同融合方法在不同模型融合规模下的跨任务性能对比：KG-MFTO在所有融合规模下均优于基线方法，且其性能随模型数量增加而持续提升，展现出优异的可扩展性。其中，跨任务平均性能通过对各任务归一化后的测试结果取均值得到，以消除任务间尺度差异的影响。}[The Impact of Merging Scale on Cross-Task Performance]{Cross-task performance comparison of different merging methods across varying model merging scales: KG-MFTO outperforms baseline methods at all merging scales, with its performance continuously improving as the number of models increases, demonstrating excellent scalability. The cross-task average performance is calculated by averaging the normalized test results across tasks to eliminate the impact of scale differences between tasks.}
	\label{fig:merge-performance-vs-num-models}
\end{figure}

首先关注不同方法随融合模型数量增加时的整体性能趋势。如图 \ref{fig:merge-performance-vs-num-models} 所示，纵轴为归一化后平均得分（0–100），横轴为融合模型数 $N$。从两个模型开始逐步增加专家模型，可以观察到静态方法（Model Soup 与 Task Arithmetic）在初期仍有一定提升，但当 $N>4$ 后曲线几乎停滞甚至出现轻微回落，反映出简单线性组合无法应对多专家间的冲突。改进的静态方法 TIES 与 DARE-TIES 在 $N=3$ 到 5 阶段增速略好于简单平均，但在 $N\ge6$ 时也趋于平台，最终得分仅在 63–65 分区间，说明基于符号对齐或随机失活的启发式只能部分缓解干扰，其收益有限。
相比之下，演化搜索基线 EOMMR 在中等规模（3–5 模型）表现突出，整体得分高出静态方法约 3–4 分，体现了自适应搜索在融合权重确定上的优势。但随着 $N$ 继续增大，其曲线斜率明显减小，6 至 7 模型间的提升不足 0.5 分，出现边际收益递减，说明全局黑盒搜索在高维空间的效率受限。
本章提出的 KG-MFTO 曲线在全范围内保持持续上升趋势，即使在 7 模型融合时仍较 6 模型提升约 1 分（约 +1.3 个百分点），最终达到 71 分左右，显著高于 EOMMR 的 69.6 分。这表明，当融合规模扩大时，只有 KG-MFTO 能够持续挖掘新增专家的互补信息，实现近似线性的性能累积，而其它方法均或多或少陷入瓶颈。结果验证了知识图谱引导的多形态迁移优化在解决大规模融合中能力冲突与信息利用平衡问题上的有效性。

\begin{figure}
	\centering
	\includegraphics[width=0.67\textwidth]{KG-MFTO/figure2_single_task_coding.pdf}
	\bicaption[模型融合数量对单任务性能的影响]{不同模型融合方法在 HumanEval 上的性能与融合模型数量的关系。模型数量的增加会导致单个任务上的性能衰减，KG-MFTO 在多模型融合场景下表现出更优的稳健性。}[Effect of Ensemble Size on Single-Task Performance]{Performance of various model merging methods on the HumanEval benchmark versus the number of fused models. Increasing the number of models leads to performance degradation on individual tasks, while KG-MFTO demonstrates superior robustness in scenarios involving more model fusions.}
	\label{fig:task-wise-prr}
\end{figure}

为了进一步揭示模型冲突在扩展融合规模时的影响，选取 HumanEval 代码生成任务作为代表，观察单任务性能的变化趋势。如图 \ref{fig:task-wise-prr} 所示，纵轴为融合模型在 HumanEval 上的 pass@1 原始准确率（\%），横轴为融合模型数量 $N$。从两模型融合开始，性能便出现轻微下降：当仅融合两至三个代码相关模型时仍能保持较高水平（约 50\% pass@1，即 90\% PRR 以上），但随着非代码领域模型陆续加入，下降趋势逐渐加剧。在包含 7 个模型时，融合模型的 pass@1 降至约 45\% 以下，PRR 约 89\%，明显低于原代码专家模型。
静态方法（Model Soup、Task Arithmetic）下降最为显著；TIES 与 DARE-TIES 略有缓解但仍难以完全抑制负迁移；EOMMR 通过全局优化在 5 模型之前能部分稳定单任务性能，但在 $N\ge6$ 后同样出现缓慢下滑。相较之下， KG-MFTO 在整个过程中保持最高且最平缓的下降曲线：其 pass@1 的初始值为 51\%，最终约为 49\%，几乎保留了全部初始优势。这表明知识引导的热启动与课程规划能有效避免任务间冲突传播，使单任务能力在多模型融合中得到最大限度的保留。该结果直观地展示了“任务冲突曲线”的控制效果，也从单任务角度佐证了 KG-MFTO 的稳健性。

表 \ref{tab:detail-results} 汇总了在融合全部 7 个模型时，不同方法在四个代表性任务（指令 IFEval、中文 CMMLU、数学 MATH、代码 HumanEval）上的性能保留率 (PRR) 及对应绝对分数。可以看出，简单平均与 Task Arithmetic 的平均 PRR 仅约 65\%，其中在数学与代码任务上损失最为严重（约 50\% 保留）。TIES 和 DARE 单独使用时 PRR 提升至 71–72\%，二者结合的 DARE+TIES 进一步达到 74\%，说明参数筛选和符号对齐确能在一定程度上缓解冲突。
在自适应方法中， EOMMR 凭借演化搜索确定融合权重，取得了 78.3\% 的平均 PRR，显著超越所有静态方法，尤其在数学与代码任务上分别保留了 62\% 与 86\% 的性能，展示了优化策略在协调冲突方面的潜力。然而， EOMMR 的整体得分仍低于理想上限，且在扩展任务维度时增益有限。
相比之下， KG-MFTO 在四项任务上均取得最高分：指令 57.4 （77\% PRR）、中文 52.3 （91\%）、数学 26.1 （64\%）、代码 49.2 （89\%），平均 PRR 达 80.4\%，较 EOMMR 再提升约 2\%。其在最易受冲突影响的数学与代码任务上分别领先 EOMMR 约 +2\% 与 +3\%，表明知识图谱驱动的均值/协方差热启动显著提高了融合优化的质量与效率。总体而言， KG-MFTO 不仅在平均表现上优于所有对比方法，也在任务间保持最平衡的性能分布，体现出持续的可扩展融合能力。

\begin{figure}
	\centering
	\includegraphics[width=0.67\textwidth]{KG-MFTO/figure3_convergence_vs_evals.pdf}
	\bicaption[评估效率对比]{KG-MFTO与EOMMR在融合优化过程中的性能提升与评估次数关系。KG-MFTO在更少的评估次数下实现了更高的最终性能，显示出知识引导的效率优势。}[Evaluation efficiency comparison]{Relationship between performance improvement and evaluation count during merging optimization for KG-MFTO and EOMMR. KG-MFTO reaches higher final performance with fewer evaluations, highlighting the efficiency of knowledge guidance.}
	\label{fig:perf-vs-eval-count}
\end{figure}

\begin{table}[tb]
	\centering
	\bicaption[模型融合方法在不同任务上的性能对比]{各融合方法在 7 模型融合任务上的性能对比。表中给出指令、中文、数学、代码（HumanEval）四项任务的性能保留率（PRR，\%）及（括号内对应的融合模型绝对得分）。最佳结果以\textbf{粗体}标出；单模型上限为任务对应的单模型自身最佳性能（作为100\%标准）。}[Performance comparison of model merging methods across different tasks]{Performance comparison of different merging methods on the seven-model merging task. The table reports PRR (\%) for instruction, Chinese, mathematics, and code (HumanEval) along with the absolute scores of the fused models in parentheses. Best results are highlighted in bold; single-model upper bounds correspond to the best specialist performance for each task (100\% standard).}
	\label{tab:detail-results}
	\resizebox{\textwidth}{!}{
		\small\begin{tabular}{lccccc}
			\toprule
			\textbf{融合方法}    & \textbf{IFEval (指令)} & \textbf{CMMLU (中文)}  & \textbf{MATH (数学)}   & \textbf{HumanEval (代码)} & \textbf{平均PRR}  \\
			\midrule
			\textit{单模型上限}   & 100\% (75.0)         & 100\% (57.4)         & 100\% (40.5)         & 100\% (55.0)            & 100.0\%         \\
			\midrule
			Model Soup       & 61\% (46.0)          & 77\% (44.2)          & 52\% (21.0)          & 73\% (40.0)             & 65.7\%          \\
			Task Arithmetic  & 60\% (45.0)          & 76\% (43.5)          & 49\% (19.9)          & 75\% (41.4)             & 65.0\%          \\
			TIES             & 68\% (50.8)          & 85\% (48.9)          & 56\% (22.7)          & 81\% (44.3)             & 72.4\%          \\
			DARE             & 66\% (49.2)          & 83\% (47.5)          & 54\% (22.0)          & 83\% (45.4)             & 71.3\%          \\
			DARE+TIES        & 69\% (52.0)          & 87\% (49.7)          & 57\% (23.1)          & 84\% (46.0)             & 74.1\%          \\
			EOMMR            & 75\% (56.0)          & 90\% (51.6)          & 62\% (25.3)          & 86\% (47.3)             & 78.3\%          \\
			\textbf{KG-MFTO} & \textbf{77\% (57.4)} & \textbf{91\% (52.3)} & \textbf{64\% (26.1)} & \textbf{89\% (49.2)}    & \textbf{80.4\%} \\
			\bottomrule
		\end{tabular}
	}
\end{table}

图 \ref{fig:perf-vs-eval-count} 展示了在单次融合优化过程中，EOMMR 与 KG-MFTO 的性能收敛曲线。横轴为 CMA-ES 候选解的评估次数（evaluations），纵轴为归一化后平均得分（0–100）。结果显示，EOMMR 作为标准演化搜索，性能提升相对缓慢，约在 200 次评估后达到 69.6 分并趋于饱和；而 KG-MFTO 在相同条件下实现了显著加速，仅 70 次评估便能超过 69 分，并在 120 次左右达到 71 分的稳定上限。
这种加速来源于外层知识图谱的作用，在内层 CMA-ES 启动时，KG-MFTO 已经从历史形式求解中获得协同先验与初始化分布，因此能够在搜索初期快速收敛到高质量区域。换言之，外层的“经验积累”（Table \ref{tab:kg-quality}）通过均值与协方差热启动，在内层搜索中转化为“评估效率”。
从定量角度看，在相同的 200 次评估预算下，KG-MFTO 的最终得分比 EOMMR 高约 1.4 分（≈ 2\% PRR 提升），而在达到相同性能（≈ 69.5 分）时所需评估次数减少约 60\%，充分证明了知识引导搜索的样本效率优势。

\mysubsection{消融实验}
\label{sec:ch5-6-3-ablation-study}

为探究知识迁移机制在优化过程中发挥的作用，记录了 KG-MFTO 在不断求解新形式时，知识图谱质量和算法性能随经验积累的变化。如表所示，将总评估次数 $B$ 分别取 25、50、100，统计此时知识图谱中模型--模型协同预测与实际最优权重之间的 Spearman 秩相关系数 $\rho$，以及算法在解决一个全新融合问题（未见过的形式）时直接使用 GNN 建议解（无需优化）的启动性能。结果显示，随着算法求解的形式增多，知识图谱对模型关系的把握显著提升：$\rho$ 从 25 次后的 0.31 提高到 100 次后的 0.62，表明图谱中学到的协同分数与实际观测到的模型重要性排序越来越一致。同时，不确定度随着观测次数增加而降低（未在表中列出），反映出图谱知识变得更可靠。更直观的是，算法在未优化时就能给出的初始宏观得分（相当于直接采用 GNN 预测的融合权重所得到的性能）逐步攀升：从 68.5 增长至 73.9。这说明，通过反复的知识积累和 GNN 学习，KG-MFTO 学会了如何基于以往经验对新问题做出较好决策，使其对融合的驾驭能力越来越强。这种优化过程中的自我蒸馏现象充分证明了知识迁移的价值：在解决主问题的同时，也在训练一个代理模型，使其渐渐接近主问题的解分布，从而实现优化的经验重用和收益递增。

\begin{table}[tb]
	\centering
	\bicaption[求解形式数量对知识图谱的影响]{知识图谱质量随求解形式数量的提升趋势与饱和验证。$\rho$ 表示知识图谱预测的协同值与最终融合权重之间的 Spearman 相关系数；启动得分为无需搜索、直接采用知识图谱/GNN 建议配方时的归一化平均得分（0–100）。}[The Impact of The Number of Forms Solved on Knowledge Graphs]{Trend and saturation verification of knowledge-graph quality with increasing number of solved forms. $\rho$ denotes the Spearman correlation between predicted synergy scores and final merging weights; the startup score reports the normalized overall score (0–100) achieved by directly adopting the KG/GNN-suggested merging without search.}
	\label{tab:kg-quality}
	\small
	\begin{tabular}{ccccc}
		\toprule
		\textbf{已求解形式数量}     & 25   & 50   & 100  & 150  \\
		\midrule
		$\rho$(预测协同 vs 最优权重) & 0.31 & 0.47 & 0.62 & 0.63 \\
		启动得分 (0–100)         & 63.4 & 65.2 & 66.1 & 66.2 \\
		\bottomrule
	\end{tabular}
\end{table}

表 \ref{tab:kg-quality} 展示了随着求解形式数量的增加，知识图谱质量与启动性能的演化趋势。当仅求解约 25 个形式时，预测协同值与最终融合权重之间的相关性 $\rho$ 仅 0.31，说明此时知识仍接近随机，启动得分仅 63 左右。随着已求解形式增至 50 个，图谱开始积累可泛化的结构关系， $\rho$ 提升至 0.47，启动得分上升到 65 附近。继续扩展至 100 个形式后， $\rho$ 约 0.62，得分达到 66 左右。继续增加至 150 forms 后，提升幅度不足 0.1 分，表明知识图谱已基本填满，后续增量带来的经验收益极小。换言之，系统的学习效率在此阶段达到稳定上限，其后性能提升主要依赖于搜索层面的细化而非知识积累。


\mysubsection{闭环融合过程分析}
\label{sec:ch5-6-4-closed-loop-merging-analysis}

除了最终性能指标，还对 KG-MFTO 在融合过程中的行为进行了分析，以深入理解其发挥作用的原理。首先，关注课程规划器选择融合顺序的策略：在多次独立运行中观察到，KG-MFTO 往往倾向先融合在某些任务上协同效应明显的模型组合。例如，在本设定下，课程规划器很早便发现 M3（数学模型）和 M4（代码模型）的组合互补性强，往往在 $\ell=2$ 级别就重点优化该对模型在数学和代码任务上的融合，得到两者兼顾的加权方案；相反，M7（安全对齐模型）由于在大多数通用任务上不提升性能甚至有负面影响，知识图谱为其赋予了较高的不确定度和负协同值，课程规划器选择将 M7 的融合推迟到最后的阶段。在 $\ell=7$ 全融合时，算法只为 M7 分配了约 0.5 的较低权重，成功将其安全属性整合进模型而未让其主导其他能力的表现。这说明 KG-MFTO 能够智能地安排融合顺序：先组合那些显然互补的模型来攫取高收益，后处理具有冲突风险的模型并为其降低权重，从而最大化整体收益。

其次，检查了最终融合模型的参数组成。通过对比融合模型与各原始模型参数的差异，发现融合模型中约有 65\% 的参数值几乎与某个原模型对应层的参数相等，而剩余约 35\% 的参数则与任何单一模型值都不接近，可以视为全新生成的折中参数。进一步分析这些折中参数的分布：它们主要集中在 Transformer 网络的中高层，而低层如嵌入层和前几层注意力层，大部分直接拷贝自某个专家模型（其中以代码模型 M4 的底层参数被大量继承为代表）。这表明，该方法自适应地学习了层次化的融合策略：对于模型底层那些较通用的特征表示，选择最擅长该领域的单模型参数即可；而对于模型高层的行为决策部分，则通过演化搜索产生新参数以折中不同模型的输出分布。这种现象也得到其它研究的印证，即不同模型在浅层特征上往往相似度高而在高层语义上差异大，融合时高层需要更多调整。本章方法无需人工指定，便通过知识驱动的优化自动实现了这一分层融合，很好地保留了各模型的底层共性知识，并对冲了高层决策的冲突。

最后，将 KG-MFTO 融合模型与各单模型在输出上的差异做了定性比较。在指令和常识对话测试中，融合模型能够同时展现出多模型的长处：既具备 M1 的流畅回应能力，又融入了 M7 的安全准则（对不当请求会礼貌拒绝），同时还能调用 M5 的常识在开放问题上给出合理推理。对于数学和代码问题，融合模型的解答步骤和编码风格有时显示出 M3 和 M4 的痕迹，但总体较它们更加稳健，这是因为融合模型得到了一种融合模型表现出一种协同校正机制。当 M3 偏向的解法可能出错时，来自 M1 常规能力的约束会校正它。当 M4 输出代码有纰漏时，M1、M5 等的语言常识有时会发现异常并进行修正。当然，在非常专门或复杂的问题上，融合模型偶尔也会受干扰出现一些混淆错误，但总体频率显著低于简单平均融合。可见，通过显式建模和优化，KG-MFTO 在一定程度上实现了知识的优势互补并降低了劣势的相互影响。

综上，实验结果全面验证了本章提出方法在多模型融合任务上的有效性。KG-MFTO不仅显著提升了融合模型的性能，使其在多个任务上达到接近专长模型的水准；更为重要的是，它成功解决了随着融合规模扩大而出现的效率瓶颈与冲突难题，实现了可扩展、高效的融合优化。这一成果证明了知识迁移与课程优化思想在复杂模型构建问题上的巨大潜力。

\mysection{本章小结}
\label{sec:ch5-7-chapter-summary}

本章围绕参数层的高效模型融合问题，提出了知识引导的多形式优化框架 KG-MFTO，并通过理论分析和实验证明了其有效性。将大模型免重复训练融合重新表述为一个可逐步求解的多形式迁移优化任务，利用知识图谱累积模型关系知识，课程规划器自适应地选择子问题序列，演化求解器在知识指导下高效搜索融合权重，从而在无需任何参数训练的前提下，实现多个专长 LLM 能力的有机整合。与传统方法相比，KG-MFTO 能够更好地缓解模型间的冲突，保留各模型原有专长的同时取得性能的互补增益；同时，它大幅降低了搜索的复杂度和开销，使得融合过程可扩展到更多模型、更高维参数空间。在实证研究中，融合 7 个不同领域的大模型后，KG-MFTO 得到的模型在多个任务上的性能接近甚至超过各单领域模型，并显著优于静态融合和无指导搜索的结果。这证明了通过显式建模知识关系和跨子问题迁移优化，可以突破以往融合方法在规模和效果上的局限。

本章的方法为深度模型的模块化复用提供了一种新思路：即通过分解和迁移来解决整体优化难题，避免一步到位的暴力过程。这一思路不仅适用于大语言模型的融合，对于其他需要组合多个已训练组件的场景（例如多模态模型融合、专家系统集成等）也有潜在借鉴意义。当然，本章工作仍有改进空间，例如知识图谱构建目前依赖简单的指标，未来可引入更复杂的关系挖掘；又如在更大规模（数十模型）的情境下，课程规划和搜索策略还需进一步验证和优化。在下一章中，将对全文的研究进行总结，讨论包括本章在内的各层级高效模型构建方法之间的联系，并展望未来可能的发展方向。

\end{document}
