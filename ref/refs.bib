@misc{epoch_ai_model_size,
  author       = {{Epoch AI}},
  title        = {AI Model Size Trends},
  year         = {2023},
  howpublished = {\url{https://epochai.org/}}
}

@inproceedings{gpt3_paper,
  author    = {Tom B. Brown and others},
  title     = {Language Models are Few-Shot Learners},
  booktitle = {Advances in Neural Information Processing Systems 33},
  year      = {2020}
}

@misc{palm_paper,
  title         = {PaLM: Scaling Language Modeling with Pathways},
  author        = {Aakanksha Chowdhery and others},
  year          = {2022},
  eprint        = {2204.02311},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{training_cost_analysis,
  author = {{Various Sources}},
  title  = {Analysis of Large Model Training Costs},
  year   = {2024}
}

@article{hinton2015distilling,
  title   = {Distilling the knowledge in a neural network},
  author  = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal = {arXiv preprint arXiv:1503.02531},
  year    = {2015}
}

@article{gou2021knowledge,
  title     = {Knowledge distillation: A survey},
  author    = {Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal   = {International Journal of Computer Vision},
  volume    = {129},
  number    = {6},
  pages     = {1789--1819},
  year      = {2021},
  publisher = {Springer}
}

@article{tian2019contrastive,
  title   = {Contrastive representation distillation},
  author  = {Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  journal = {arXiv preprint arXiv:1910.10699},
  year    = {2019}
}

@article{elsken2019neural,
  title   = {Neural architecture search: A survey},
  author  = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
  journal = {Journal of Machine Learning Research},
  volume  = {20},
  year    = {2019}
}

@inproceedings{zoph2018learning,
  title     = {Learning transferable architectures for scalable image recognition},
  author    = {Zoph, Barret and Le, Quoc V and others},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {8697--8710},
  year      = {2018}
}

@article{chen2021bridge,
  title   = {Bridge the gap between domains: Transferable neural architecture search},
  author  = {Chen, Zixuan and Li, Zecheng and He, Hai-Tao and Li, Yixuan and Wang, Xiaolin},
  journal = {arXiv preprint arXiv:2104.00939},
  year    = {2021}
}

@article{wortsman2022model_soup,
  title         = {Model Soups: Averaging Weights of Multiple Fine-Tuned Models Improves Accuracy without Increasing Inference Time},
  author        = {Mitchell Wortsman and Gabriel Ilharco and Samir Yitzhak Gadre and Rebecca Roelofs and Raphael Gontijo-Lopes and Ari S. Morcos and Hongseok Namkoong and Ali Farhadi and Yair Carmon and Simon Kornblith and Ludwig Schmidt},
  year          = {2022},
  eprint        = {2203.05482},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{ilharco2022task_arithmetic,
  title         = {Editing Models with Task Arithmetic},
  author        = {Gabriel Ilharco and Marco Tulio Ribeiro and Mitchell Wortsman and Suchin Gururangan and Ludwig Schmidt and Hannaneh Hajishirzi and Ali Farhadi},
  year          = {2022},
  eprint        = {2212.04089},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{yadav2023ties_merging,
  title         = {TIES-Merging: Resolving Interference When Merging Models},
  author        = {Prateek Yadav and Derek Tam and Leshem Choshen and Colin Raffel and Mohit Bansal},
  year          = {2023},
  eprint        = {2306.01708},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{yu2023dare,
  title   = {DARE: Disentangling, Aligning, and Fusing Representations for Cross-Domain Recommendation},
  author  = {Yu, Jian-Huang and Lin, You-Wei and Shou, De-Chuan and Chen, Hsin-Hsi},
  year    = {2023},
  journal = {arXiv preprint arXiv:2305.09932}
}

@inproceedings{prompt_distiller_paper,
  title     = {Prompt-Distiller: Few-Shot Knowledge Distillation for Prompt-Based Language Learners with Dual Contrastive Learning},
  author    = {Author 1 and Author 2},
  booktitle = {Proceedings of a Top Conference},
  year      = {2023}
}

@inproceedings{esto_paper,
  title     = {Evolutionary Transfer Neural Architecture Search Across Spaces via Representation Learning},
  author    = {Author 3 and Author 4},
  booktitle = {Proceedings of another Top Conference},
  year      = {2023}
}

@inproceedings{kg_mfto_paper,
  title     = {KG-MFTO: Parameter Fusion for Multi-Form Transfer Optimization via Knowledge Graph},
  author    = {Author 5 and Author 6},
  booktitle = {Proceedings of yet another Top Conference},
  year      = {2023}
}

@article{DBLP:journals/corr/abs-2003-08271,
  author  = {Xipeng Qiu and
             Tianxiang Sun and
             Yige Xu and
             Yunfan Shao and
             Ning Dai and
             Xuanjing Huang},
  title   = {Pre-trained Models for Natural Language Processing: {A} Survey},
  journal = {CoRR},
  volume  = {abs/2003.08271},
  year    = {2020}
}
@article{DBLP:journals/corr/abs-2106-07139,
  author  = {Xu Han and
             Zhengyan Zhang and
             Ning Ding and
             Yuxian Gu and
             Xiao Liu and
             Yuqi Huo and
             Jiezhong Qiu and
             Liang Zhang and
             Wentao Han and
             Minlie Huang and
             Qin Jin and
             Yanyan Lan and
             Yang Liu and
             Zhiyuan Liu and
             Zhiwu Lu and
             Xipeng Qiu and
             Ruihua Song and
             Jie Tang and
             Ji{-}Rong Wen and
             Jinhui Yuan and
             Wayne Xin Zhao and
             Jun Zhu},
  title   = {Pre-Trained Models: Past, Present and Future},
  journal = {CoRR},
  volume  = {abs/2106.07139},
  year    = {2021}
}
@article{DBLP:journals/corr/abs-2107-13586,
  author  = {Pengfei Liu and
             Weizhe Yuan and
             Jinlan Fu and
             Zhengbao Jiang and
             Hiroaki Hayashi and
             Graham Neubig},
  title   = {Pre-train, Prompt, and Predict: {A} Systematic Survey of Prompting
             Methods in Natural Language Processing},
  journal = {CoRR},
  volume  = {abs/2107.13586},
  year    = {2021}
}
@inproceedings{DBLP:conf/eacl/SchickS21,
  author    = {Timo Schick and
               Hinrich Sch{\"{u}}tze},
  title     = {Exploiting Cloze-Questions for Few-Shot Text Classification and Natural
               Language Inference},
  booktitle = {EACL},
  pages     = {255--269},
  year      = {2021}
}
@inproceedings{DBLP:conf/acl/GaoFC20,
  author    = {Tianyu Gao and
               Adam Fisch and
               Danqi Chen},
  title     = {Making Pre-trained Language Models Better Few-shot Learners},
  booktitle = {ACL/IJCNLP},
  pages     = {3816--3830},
  year      = {2021}
}
@article{DBLP:journals/corr/abs-2103-10385,
  author  = {Xiao Liu and
             Yanan Zheng and
             Zhengxiao Du and
             Ming Ding and
             Yujie Qian and
             Zhilin Yang and
             Jie Tang},
  title   = {{GPT} Understands, Too},
  journal = {CoRR},
  volume  = {abs/2103.10385},
  year    = {2021}
}
@article{DBLP:journals/corr/abs-2109-07684,
  author  = {Genta Indra Winata and
             Andrea Madotto and
             Zhaojiang Lin and
             Rosanne Liu and
             Jason Yosinski and
             Pascale Fung},
  title   = {Language Models are Few-shot Multilingual Learners},
  journal = {CoRR},
  volume  = {abs/2109.07684},
  year    = {2021}
}
@article{DBLP:journals/corr/abs-2109-01652,
  author  = {Jason Wei and
             Maarten Bosma and
             Vincent Y. Zhao and
             Kelvin Guu and
             Adams Wei Yu and
             Brian Lester and
             Nan Du and
             Andrew M. Dai and
             Quoc V. Le},
  title   = {Finetuned Language Models Are Zero-Shot Learners},
  journal = {CoRR},
  volume  = {abs/2109.01652},
  year    = {2021}
}
@article{DBLP:journals/ijcv/GouYMT21,
  author  = {Jianping Gou and
             Baosheng Yu and
             Stephen J. Maybank and
             Dacheng Tao},
  title   = {Knowledge Distillation: {A} Survey},
  journal = {Int. J. Comput. Vis.},
  volume  = {129},
  number  = {6},
  pages   = {1789--1819},
  year    = {2021}
}
@article{DBLP:journals/corr/abs-1903-12136,
  author  = {Raphael Tang and
             Yao Lu and
             Linqing Liu and
             Lili Mou and
             Olga Vechtomova and
             Jimmy Lin},
  title   = {Distilling Task-Specific Knowledge from {BERT} into Simple Neural
             Networks},
  journal = {CoRR},
  volume  = {abs/1903.12136},
  year    = {2019}
}
@inproceedings{DBLP:conf/emnlp/SunCGL19,
  author    = {Siqi Sun and
               Yu Cheng and
               Zhe Gan and
               Jingjing Liu},
  title     = {Patient Knowledge Distillation for {BERT} Model Compression},
  booktitle = {EMNLP-IJCNLP},
  pages     = {4322--4331},
  year      = {2019}
}
@inproceedings{DBLP:conf/emnlp/JiaoYSJCL0L20,
  author    = {Xiaoqi Jiao and
               Yichun Yin and
               Lifeng Shang and
               Xin Jiang and
               Xiao Chen and
               Linlin Li and
               Fang Wang and
               Qun Liu},
  title     = {TinyBERT: Distilling {BERT} for Natural Language Understanding},
  booktitle = {EMNLP (Findings)},
  pages     = {4163--4174},
  year      = {2020}
}
@article{DBLP:journals/corr/abs-2110-04725,
  author  = {Shaohua Wu and
             Xudong Zhao and
             Tong Yu and
             Rongguo Zhang and
             Chong Shen and
             Hongli Liu and
             Feng Li and
             Hong Zhu and
             Jiangang Luo and
             Liang Xu and
             Xuanwei Zhang},
  title   = {Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and
             Few-Shot Learning},
  journal = {CoRR},
  volume  = {abs/2110.04725},
  year    = {2021}
}
@inproceedings{DBLP:conf/emnlp/ShinRLWS20,
  author    = {Taylor Shin and
               Yasaman Razeghi and
               Robert L. Logan IV and
               Eric Wallace and
               Sameer Singh},
  title     = {AutoPrompt: Eliciting Knowledge from Language Models with Automatically
               Generated Prompts},
  booktitle = {EMNLP},
  pages     = {4222--4235},
  year      = {2020}
}
@article{DBLP:journals/corr/abs-2110-07602,
  author  = {Xiao Liu and
             Kaixuan Ji and
             Yicheng Fu and
             Zhengxiao Du and
             Zhilin Yang and
             Jie Tang},
  title   = {P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally
             Across Scales and Tasks},
  journal = {CoRR},
  volume  = {abs/2110.07602},
  year    = {2021}
}
@inproceedings{DBLP:conf/acl/HambardzumyanKM20,
  author    = {Karen Hambardzumyan and
               Hrant Khachatrian and
               Jonathan May},
  title     = {{WARP:} Word-level Adversarial ReProgramming},
  booktitle = {ACL/IJCNLP},
  pages     = {4921--4933},
  year      = {2021}
}
@inproceedings{DBLP:conf/naacl/WilliamsNB18,
  author    = {Adina Williams and
               Nikita Nangia and
               Samuel R. Bowman},
  title     = {A Broad-Coverage Challenge Corpus for Sentence Understanding through
               Inference},
  booktitle = {NAACL-HLT},
  pages     = {1112--1122},
  year      = {2018}
}
@inproceedings{DBLP:conf/emnlp/BowmanAPM15,
  author    = {Samuel R. Bowman and
               Gabor Angeli and
               Christopher Potts and
               Christopher D. Manning},
  title     = {A large annotated corpus for learning natural language inference},
  booktitle = {EMNLP},
  pages     = {632--642},
  year      = {2015}
}
@inproceedings{DBLP:conf/semeval/DzikovskaNBLGBC13,
  author    = {Myroslava O. Dzikovska and
               Rodney D. Nielsen and
               Chris Brew and
               Claudia Leacock and
               Danilo Giampiccolo and
               Luisa Bentivogli and
               Peter Clark and
               Ido Dagan and
               Hoa Trang Dang},
  title     = {SemEval-2013 Task 7: The Joint Student Response Analysis and 8th Recognizing
               Textual Entailment Challenge},
  booktitle = {SemEval@NAACL-HLT},
  pages     = {263--274},
  year      = {2013}
}
@inproceedings{DBLP:conf/naacl/DengW15,
  author    = {Lingjia Deng and
               Janyce Wiebe},
  title     = {{MPQA} 3.0: An Entity/Event-Level Sentiment Corpus},
  booktitle = {NAACL-HLT},
  pages     = {1323--1328},
  year      = {2015}
}
@inproceedings{DBLP:conf/emnlp/SocherPWCMNP13,
  author    = {Richard Socher and
               Alex Perelygin and
               Jean Wu and
               Jason Chuang and
               Christopher D. Manning and
               Andrew Y. Ng and
               Christopher Potts},
  title     = {Recursive Deep Models for Semantic Compositionality Over a Sentiment
               Treebank},
  booktitle = {EMNLP},
  pages     = {1631--1642},
  year      = {2013}
}
@inproceedings{DBLP:conf/acl/PangL05,
  author    = {Bo Pang and
               Lillian Lee},
  title     = {Seeing Stars: Exploiting Class Relationships for Sentiment Categorization
               with Respect to Rating Scales},
  booktitle = {ACL},
  pages     = {115--124},
  year      = {2005}
}
@article{DBLP:journals/nle/LiR06,
  author  = {Xin Li and
             Dan Roth},
  title   = {Learning question classifiers: the role of semantic information},
  journal = {Nat. Lang. Eng.},
  volume  = {12},
  number  = {3},
  pages   = {229--249},
  year    = {2006}
}
@article{DBLP:journals/corr/abs-1907-11692,
  author  = {Yinhan Liu and
             Myle Ott and
             Naman Goyal and
             Jingfei Du and
             Mandar Joshi and
             Danqi Chen and
             Omer Levy and
             Mike Lewis and
             Luke Zettlemoyer and
             Veselin Stoyanov},
  title   = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal = {CoRR},
  volume  = {abs/1907.11692},
  year    = {2019}
}
@article{DBLP:journals/corr/abs-1807-03748,
  author  = {A{\"{a}}ron van den Oord and
             Yazhe Li and
             Oriol Vinyals},
  title   = {Representation Learning with Contrastive Predictive Coding},
  journal = {CoRR},
  volume  = {abs/1807.03748},
  year    = {2018}
}
@inproceedings{DBLP:conf/aaai/FuZYTLLL21,
  author    = {Hao Fu and
               Shaojun Zhou and
               Qihong Yang and
               Junjie Tang and
               Guiquan Liu and
               Kaikui Liu and
               Xiaolong Li},
  title     = {{LRC-BERT:} Latent-representation Contrastive Knowledge Distillation
               for Natural Language Understanding},
  booktitle = {AAAI},
  pages     = {12830--12838},
  year      = {2021}
}
@article{DBLP:journals/corr/abs-1908-08962,
  author  = {Iulia Turc and
             Ming{-}Wei Chang and
             Kenton Lee and
             Kristina Toutanova},
  title   = {Well-Read Students Learn Better: The Impact of Student Initialization
             on Knowledge Distillation},
  journal = {CoRR},
  volume  = {abs/1908.08962},
  year    = {2019}
}
